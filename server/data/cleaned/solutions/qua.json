[
  {
    "id": "QUA-1",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because a point estimate is used to calculate a confidence interval; Point estimate Â± Reliability factor x Standard error = confidence interval."
      },
      {
        "isCorrect": true,
        "reason": "because a confidence interval for a parameter is calculated as: Point estimate Â± Reliability factor x Standard error, where standard error is the standard error of the sample statistic providing the point estimate. Thus, sampling error is not part of the calculation. Sampling error is the difference between the observed value of a statistic and the quantity it is intended to estimate. It is because of sampling error that confidence intervals are used."
      },
      {
        "isCorrect": false,
        "reason": "because a reliability factor is used to calculate a confidence interval, Point estimate Â± Reliability factor x Standard error = confidence interval."
      }
    ],
    "note": "Quantitative Methods: compare and contrast simple random, stratified random, cluster, convenience, and judgmental sampling and their implications for sampling error in an investment problem"
  },
  {
    "id": "QUA-2",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it uses the forecasted value of the independent variable to construct the prediction interval rather than the predicted value of the dependent variable. In other words, it assumes that the interval is given by ð‘‹ð‘“Â± ð‘¡ð‘ð‘Ÿð‘–ð‘¡ð‘–ð‘ð‘Žð‘™ ð‘“ð‘œð‘Ÿ ð‘Ž/2 ð‘†ð‘¡: 3.5 % Ã— 1.4% â‰ˆ (0.7%, 6.3%)."
      },
      {
        "isCorrect": true,
        "reason": "because a forecasted value of the dependent variable, ð‘Œð‘“, is determined using the estimated intercept and slope, as well as the expected or forecasted independent variable, ð‘‹ð‘“: ð‘Œð‘“= ð‘0 + ðµð‘“ð‘‹ð‘“ \" where ð‘0 and ð‘1, are the estimated intercept and slope coefficients, respectively. Hence, ð‘Œð‘“= 1.2% + 1.0 x 3.5% = 4.7%.\nNext, the prediction interval is ð‘‹ð‘“Â± ð‘¡ð‘ð‘Ÿð‘–ð‘¡ð‘–ð‘ð‘Žð‘™ ð‘“ð‘œð‘Ÿ ð‘Ž/2 ð‘†ð‘¡\" where ð‘†ð‘“, denotes the standard error of the forecast. Hence, the prediction interval is given by: 4.7% Â± 1.4% x 2.032 â‰ˆ (1.9%, 7.5%)."
      },
      {
        "isCorrect": false,
        "reason": "because it neglects the critical t - values when constructing the prediction interval. In other words, it assumes that the interval is given by ð‘Œð‘“Â± ð‘ ð‘“; 4.7% Â± 1.4% (3.3%, 6.1%)."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the predicted value for the dependent variable, and a prediction interval for it, given an estimated linear regression model and a value for the independent variable"
  },
  {
    "id": "QUA-3",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it incorrectly subtracts the dividend instead of adding it, and thus calculates HPR = ($107 - $100 - $7)/$100= $0/$100 = 0%. The same result is obtained if the holding period return is calculated as R = ($100 - $107 + $7)/$107= $0/S107 = 0%."
      },
      {
        "isCorrect": false,
        "reason": "because it omits the dividend and calculates R = ($107 - $100)/$100 = $7/$100 = 7%. It is also the ratio of the dividend received over the initial investment, $7/$100 = 7%."
      },
      {
        "isCorrect": true,
        "reason": "because a holding period return is the return earned from holding an asset for a single specified period of time. This return can be generalized and shown as a mathematical expression in which P is the price and I is the income: R = (Pâ‚ - Po + D, VP, Thus, R = ($107 - $100 + $7)/$100 = $14/$100 = 14%."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret major return measures and describe their appropriate uses"
  },
  {
    "id": "QUA-4",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because we primarily use nonparametric procedures in four situations: (1) when the data we use do not meet distributional assumptions, (2) when there are outliers, (3) when the data are given in ranks or use an ordinal scale, or (4) when the hypotheses we are addressing do not concern a parameter. This is one of the situations (situation 2) in which a nonparametric test would be appropriate."
      },
      {
        "isCorrect": false,
        "reason": "because we primarily use nonparametric procedures in four situations: (1) when the data we use do not meet distributional assumptions, (2) when there are outliers, (3) when the data are given in ranks or use an ordinal scale, or (4) when the hypotheses we are addressing do not concern a parameter. This is one of the situations (situation 3) in which a nonparametric test would be appropriate."
      },
      {
        "isCorrect": true,
        "reason": "because a nonparametric test would be less appropriate compared to other answers as in this case a parametric test can be used. We may want to test a hypothesis concerning the mean of a population but believe that neither t - nor z - distributed tests are appropriate because the sample is small and may come from a markedly non - normally distributed population. In that case, we may use a nonparametric test. In our case, the data sample is large, thus a parametric test can be used instead"
      }
    ],
    "note": "Quantitative Methods: compare and contrast parametric and nonparametric tests, and describe situations where each is the more appropriate type of test"
  },
  {
    "id": "QUA-5",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because for a Test of Mean Differences (Normally Distributed Populations, Unknown Population Variances)... when we have data consisting of paired observations from samples generated by normally distributed populations with unknown variances, a t -\ntest is based on t = (d - d0)/s, with n - 1 degrees of freedom, where n is the number of paired observations, d is the sample mean difference.... and s, is the standard error of d"
      },
      {
        "isCorrect": false,
        "reason": "because for a Test of Mean Differences (Normally Distributed Populations, Unknown Population Variances)... when we have data consisting of paired observations from samples generated by normally distributed populations with unknown variances, a t - test is based on t = (d - do)/s with n - 1 degrees of freedom, where n is the number of paired observations, d is the sample mean difference..., and s, is the standard error of d. An F - test can be appropriate for Tests Concerning Differences between the Variances of Two Populations."
      },
      {
        "isCorrect": false,
        "reason": "because for a Test of Mean Differences (Normally Distributed Populations, Unknown Population Variances)... when we have data consisting of paired observations from samples generated by normally distributed populations with unknown variances, a t - test is based on t = (d - Hdo)/s, with n - 1 degrees of freedom, where n is the number of paired observations, d is the sample mean difference.... and s, is the standard error of d. In tests concerning the variance of a single normally distributed population [not the mean difference between two populations], we make use of a chi - square test statistic."
      }
    ],
    "note": "Quantitative Methods: construct hypothesis tests and determine their statistical significance, the associated Type I and Type II errors, and power of the test given a significance level"
  },
  {
    "id": "QUA-6",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is the compound rate of return per month times 12; [(1 + 0.13100)(1/16) - 1] Ã— 12 =0.0077236 x 12 = 0.09268~ 9.3%. This is also the geometric mean return per month times 12."
      },
      {
        "isCorrect": true,
        "reason": "because a general equation to annualize returns is given, where c is the number of periods in a year. For a quarter, c = 4 and for a month, c = 12: rannual = (1 + rperiod)c - 1. That is, for 16 months, c = 12/16 = 0.75 and the annualized return is (1 + 0.13100)0.75 - 1 = 1.09672 - 1=0.09672 ~ 9.7%."
      },
      {
        "isCorrect": false,
        "reason": "because it is the arithmetic mean return per month times 12; (0.13100/16) x 12 = 0.0081875 x 12 = 0.09825~9.8%."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret major return measures and describe their appropriate uses"
  },
  {
    "id": "QUA-7",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is important to note that many cryptocurrencies have experienced high levels of price volatility. A lack of clear fundamentals underlying these currencies has contributed to their volatility."
      },
      {
        "isCorrect": false,
        "reason": "because many cryptocurrencies have a self - imposed limit on the total amount of currency they may issue."
      },
      {
        "isCorrect": true,
        "reason": "because a cryptocurrency, also known as a digital currency, operates as electronic currency and allows near - real - time transactions between parties without the need for an intermediary, such as a bank."
      }
    ],
    "note": "Alternative Investments: describe financial applications of distributed ledger technology"
  },
  {
    "id": "QUA-8",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because a growth rate (g) is calculated as g = (FV/PV)/N - 1, where FV is the future value, PV is the present value and N is the number of periods. Here, g = (1.5/1)1/4 - 1 = 0.10668~ 10.7%."
      },
      {
        "isCorrect": false,
        "reason": "because it is calculated as In(1 + 0.5/4) - 1= In(1.125) - 1=0.11778 ~11.8%."
      },
      {
        "isCorrect": false,
        "reason": "because it is calculated as: 50%/4 = 12.5%."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret annualized return measures and continuously compounded returns, and describe their appropriate uses"
  },
  {
    "id": "QUA-9",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "(P1 - 450 + 2)/450 = -10.2%"
      },
      {
        "isCorrect": false,
        "reason": ""
      },
      {
        "isCorrect": false,
        "reason": ""
      }
    ],
    "note": ""
  },
  {
    "id": "QUA-10",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the investor is foregoing higher rates of return by investing in the security with the lowest return."
      },
      {
        "isCorrect": false,
        "reason": "because 1.1% is not the most the investor is foregoing; however, it is the difference if incorrectly using the average return of the three securities."
      },
      {
        "isCorrect": true,
        "reason": "because all three securities have the same maturity and default risk so the investor is forgoing 2.2% (4.4% - 2.2%) by investing in CD 1 rather than investing in CD 3."
      }
    ],
    "note": "Quantitative Methods: interpret interest rates as required rates of return, discount rates, or opportunity costs and explain an interest rate as the sum of a real risk - free rate and premiums that compensate investors for bearing distinct types of risk"
  },
  {
    "id": "QUA-11",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because algorithmic trading requires access to low - latency networks, and with the wide - spread adoption of algorithmic trading, the need for low - latency networks has grown Low - latency systems - systems that operate on networks that communicate high volumes of data with minimal delay (latency) - are essential for automated trading applications that make decisions based on real - time prices and market events. In contrast, high - latency systems do not require access to real - time data and calculations. High - frequency trading is a form of algorithmic trading that makes use of vast quantities of\ngranular financial data (tick data, for example) to automatically place trades when certain conditions are met. Trades are executed on ultra - high - speed, low - latency networks in fractions of a second."
      },
      {
        "isCorrect": false,
        "reason": "because global financial markets have undergone substantial change as markets have fragmented into multiple trading destinations consisting of electronic exchanges, alternative trading systems, and so - called dark pools, and average trade sizes have fallen."
      },
      {
        "isCorrect": false,
        "reason": "because, although algorithmic trading is increasingly used to execute large institutional orders, it is slicing orders into smaller pieces and executing across different exchanges and trading venues. Global financial markets have undergone substantial change as markets have fragmented into multiple trading destinations consisting of electronic exchanges, alternative trading systems, and so - called dark pools, and average trade sizes have fallen."
      }
    ],
    "note": "Quantitative Methods: describe applications of Big Data and Data Science to investment management"
  },
  {
    "id": "QUA-12",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because underfitting also results in this problem. Underfitted models will typically fail to fully discover patterns that underlie the data\" and thus may not be able to accurately predict outcomes. ML involves splitting the dataset into three distinct subsets: a training dataset, a validation dataset, and a test dataset. Once an algorithm has been trained, validated, and tested, the ML model can be used to predict outcomes based on other datasets. ML models also require sufficiently large amounts of data and may not perform well where there may not be enough available data to train and validate the model."
      },
      {
        "isCorrect": false,
        "reason": "because overfitting also results in this problem. An ML model that has been overfitted is not able to accurately predict outcomes using a different dataset and may be too complex."
      },
      {
        "isCorrect": true,
        "reason": "because an ML model that has been overfitted is not able to accurately predict outcomes using a different dataset and may be too complex. Also, underfitted models will typically fail to fully discover patterns that underlie the data and thus may not be able to accurately predict outcomes."
      }
    ],
    "note": "Quantitative Methods: describe Big Data, artificial intelligence, and machine learning"
  },
  {
    "id": "QUA-13",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it recognizes the investment as a delayed annuity, but it wrongly assumes that the first annuity payment for an ordinary annuity starts immediately instead of one period away. Thus, it computes the present value of an ordinary annuity at t = 3 as PV2 =A[1 - 1/(1 + r)N]/r= $1,000 Ã— [1 - 1/(1 + 0.06)5/0.06 = $4,212.36.\nUsing the present value formula for a lump sum to bring the single cash flow from t = 3 to 1= 0, PV2 = FVN(1 + r) N = $4,212.36 (1 + 0.06) - 3= $3,536.78 ~ $3,537.\n(1) END mode: N = 5; 1= 6%, PMT= - 1,000; FV = 0; solve for PV = 4,212.36.\n(1) END mode; N = 3; 1= 6%; PMT = 0; FV = 4,212.36; solve for PV = 3,536.78 ~3,537."
      },
      {
        "isCorrect": true,
        "reason": "because by drawing a time line, the investment is recognized as a delayed annuity with the first payment starting at t=3.\nThe first step is to compute the present value of an ordinary annuity at t = 2 because the first annuity payment is\nthen one period away, as PV2 =A[1 - 1/(1 + r)N] / r = $1,000 x [1 - 1/(1 + 0.06)5/0.06 = $4,212.36.\nUsing the present value formula for a lump sum to bring the single cash flow from t = 2 to t=0, PV=FVM(1 + r) -\nN = $4,212.36 (1 + 0.06) - 2= $3,748.99 ~ $3,749.\n(1) END mode; N=5; 1= 6%; PMT= - 1,000; FV = 0; solve for PV = 4,212.36.\n(2) END mode; N = 2; 1= 6%; PMT = 0; FV = 4,212.36, solve for PV = 3,748.99 - 3,749.\nA second method to compute the present value of the investment is to recognize it as an annuity due with first payment at f = 3, and then discount back three periods using the present value formula for a lump sum. PV3= {A[1 âˆ’ 1/(1 + r)N]/r}(1 + r) = $1,000 Ã— ([1 - 1/(1 + 0.06)5/0.06) Ã— (1 + 0.06) = $4,465.11.\nUsing the present value formula for a lump sum to bring the single cash flow from t=3 to t=0, PV=FVN(1 + r) -\nN = $4,465.11 (1 + 0.06) - 3= $3,748.99 ~ $3,749.\n(1) BGN mode; N = 5; 1= 6%; PMT= - 1,000; FV = 0; solve for PV = 4,465.11.\n(2) END mode; N = 3; 1= 6%; PMT = 0; FV = 4,465.11; solve for PV=3,748.99 - 3,749.\nAnother method to compute the Correct answer is to calculate the present value of a series of equal cash flows, with the first cash flow in the third year. Using a calculator with CF0=0, CF1,=0, CF2=0, CF3=1000, CF4=1000, CF5=1000, CF6=1000, CF7=1000; I=6%; solve for NPV= 3,748.99 ~ 3,749."
      },
      {
        "isCorrect": false,
        "reason": "because it is the present value of the investment as t = 2 instead of t = 0, and it is an intermediate step in the correct calculation. It computes present value of an ordinary annuity at f = 3 as PV,= A[1 - 1/(1 + r)N]/r= $1,000 Ã— [1 - 1/(1 + 0.06)5/0.06 = $4,212.36.\nEND mode; N = 5; 1=6%; PMT = - 1,000; FV = 0; solve for PV = 4,212.36 - 4,212."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the present value (PV) of fixed - income and equity instruments based on expected future cash flows"
  },
  {
    "id": "QUA-14",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because robo - advisers typically have low fees and low account minimums, implementing their recommendations with low - cost, diversified index mutual funds or exchange - traded funds (ETFs). Fully automated digital wealth managers are one type of service in the robo - advice sector. The fully automated model does not rely on assistance from a human financial adviser. These services seek to offer a low - cost solution to investing and recommend an investment portfolio, which is often composed of ETFS."
      },
      {
        "isCorrect": false,
        "reason": "because [t]he service package [offered by fully automated digital wealth managers] may include direct deposits, periodic rebalancing, and dividend reinvestment options."
      },
      {
        "isCorrect": true,
        "reason": "because as the complexity and size of an investor's portfolio grows, robo - advisers may not be able to sufficiently address the particular preferences and needs of the investor. In the case of extremely affluent investors who may own a greater number of asset types including Alternative Investments (e.g., venture capital, private equity, hedge funds, and real estate) in addition to global stocks and bonds and have greater demands for customization, the need for a team of human advisers, each with particular areas of investment or wealth - management expertise, is likely to endure."
      }
    ],
    "note": "Quantitative Methods: describe Big Data, artificial intelligence, and machine learning"
  },
  {
    "id": "QUA-15",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because p â‰¤ 0 is the null and not the alternative hypothesis in this test. We state the null and alternative hypotheses such that they account for all possible values of the parameter. Since the alternative hypothesis is formulated using the \"suspected\" condition p > 0, the null hypothesis should be formulated using the condition Î¼ â‰¤ 0."
      },
      {
        "isCorrect": false,
        "reason": "because the \"suspected \" condition in this test is p > 0, not Î¼ â‰¥ 0. The best formulation of the alternative hypothesis uses the 'suspected' or 'hoped for condition."
      },
      {
        "isCorrect": true,
        "reason": "because despite the different ways to formulate hypotheses, we always conduct a test of the null hypothesis at the point of equality, = 0. We may have a 'suspected' or 'hoped for condition for which we want to find supportive evidence. In that case, we can formulate the alternative hypothesis as the statement that this condition is true; the null\nhypothesis that we test is the statement that this condition is not true. Here, the \"suspected\" condition is that the population's mean is greater than zero (Î¼ > 0)."
      }
    ],
    "note": "Quantitative Methods: explain hypothesis testing and its components , including statistical significance, Type I and Type II errors, and the power of a test."
  },
  {
    "id": "QUA-16",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because this is the result if the candidate uses r + c - 2=5 + 4 - 2=7, instead of the correct (r - 1)(c - 1). The incorrect formula is similar to the degrees of freedom for a test of the difference in means, which is n, + nâ‚‚ - 2."
      },
      {
        "isCorrect": true,
        "reason": "because for a contingency table we can perform a test of independence using a nonparametric test statistic that is chi - square distributed this test statistic has (r - 1)(c - 1) degrees of freedom, where r is the number of rows and c is the number of columns. Here, r = 5 and c = 4, so degrees of freedom = (5 - 1)(4 - 1)=4x3=12."
      },
      {
        "isCorrect": false,
        "reason": "because this is the result if the candidate omits ' - 1' in both factors, i.e. rc = 5 x 4 = 20, instead of the correct (r - 1)(c - 1)."
      }
    ],
    "note": "Quantitative Methods: explain tests of independence based on contingency table data"
  },
  {
    "id": "QUA-17",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because this is the result if the positions of âˆš(1 - 2) and âˆš(n - 2) are swapped, i.e. the formula used is\nN(1 - r2)/ âˆš(n - 2) = (0.6)âˆš(1 - 0.36)/ âˆš (51 - 2) = (0.6) (0.8)/7 = 0.06857 ~ 0.07."
      },
      {
        "isCorrect": true,
        "reason": "because for a Parametric Test of a Correlation if the two variables are normally distributed, we can test to determine whether the null hypothesis (Ho: p = 0) should be rejected using the sample correlation, r. The formula for the t - test is\nNâˆš(n - 2)/âˆš(1 - 2)\" = (0.6)âˆš(51 - 2)/ âˆš(1 - 0.36) = (0.6)(7)/0.8 = 5.25."
      },
      {
        "isCorrect": false,
        "reason": "because this is the result if the r in the denominator is not squared, i.e.\n(n - 2)/(1 - r) = (0.6)âˆš(51 - 2)/(1 - 0.6)=(0.6)(7)/0.63246 = 6.6408 ~ 6.64."
      }
    ],
    "note": "Quantitative Methods: explain parametric and nonparametric tests of the hypothesis that the population correlation coefficient equals zero, and determine whether the hypothesis is rejected at a given level of significance"
  },
  {
    "id": "QUA-18",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the mode, not the mean, is the measure with the highest value for a continuous negatively skewed unimodal distribution."
      },
      {
        "isCorrect": true,
        "reason": "because for the continuous negatively skewed unimodal distribution, the mean is less than the median, which is less than the mode. Therefore, the mode has the highest value."
      },
      {
        "isCorrect": false,
        "reason": "because the mode, not the median, is the measure with the highest value for a continuous negatively skewed unimodal distribution."
      }
    ],
    "note": "Quantitative Methods: interpret and evaluate measures of skewness and kurtosis to address an investment problem"
  },
  {
    "id": "QUA-19",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because Portfolio 1 has the highest expected return and the highest difference between expected return and standard deviation, but not the highest safety - first ratio."
      },
      {
        "isCorrect": false,
        "reason": "because Portfolio 2 has the lowest standard deviation of returns, but not the highest safety - first ratio. Portfolio 2 also has the highest ratio of expected return to standard deviation (ie., when the return threshold is omitted); Portfolio 1: 23%/15% ~ 1.53: Portfolio 2: 12%/6% = 2.00; Portfolio 3: 15%/8% ~ 1.88."
      },
      {
        "isCorrect": true,
        "reason": "because if returns are normally distributed, the safety - first optimal portfolio maximizes the safety - first ratio. SFRatio = [E(Rp) - R]/op. Where E(Rp) is the expected portfolio return, R, is the investor's minimum acceptable return, and a, is the standard deviation of portfolio returns. The minimum acceptable return is 5% (= â‚¬5,000/â‚¬100,000) as the investor needs to withdraw â‚¬5,000 without invading initial capital\nSFP1, = (23% - 5%)/ 15% = 1.20:\nSFP2 = (12% - 5%) / 6% ~ 1.17;\nSFP3 (15% - 5%) / 8% = 1.25.\nTherefore, Portfolio 3 is the safety - first optimal portfolio. \"The portfolio for which E(R) - Rl , is largest relative to standard deviation minimizes P(Rp< Râ‚)."
      }
    ],
    "note": "Quantitative Methods: define shortfall risk, calculate the safety - first ratio, and identify an optimal portfolio using Roy's safety - first criterion"
  },
  {
    "id": "QUA-20",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the assumption of normality requires that the residuals be normally distributed. This does not mean that the dependent and independent variables must be normally distributed."
      },
      {
        "isCorrect": false,
        "reason": "because for simple linear regression we assume that the observations (Y and X pairs) are uncorrelated with one another, meaning they are independent. If there is correlation between observations (that is, autocorrelation), they are not independent and the residuals will be correlated. As the pairs are uncorrelated, a transformation is not\nneeded because independence (uncorrelated pairs of observations) is an assumption of simple linear regression."
      },
      {
        "isCorrect": true,
        "reason": "because if the relationship between the independent variable and the dependent variable is not linear, we can often transform one or both of these variables to convert this relation to a linear form, which then allows the use of simple linear regression."
      }
    ],
    "note": "Quantitative Methods: describe different functional forms of simple linear regressions"
  },
  {
    "id": "QUA-21",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because for a continuous positively skewed unimodal distribution, the mode is less than the median, which is less than the mean."
      },
      {
        "isCorrect": false,
        "reason": "because for a continuous positively skewed unimodal distribution, the mode is less than the median, which is less than the mean. For the continuous negatively skewed unimodal distribution, the mean is less than the median, which is less than the mode."
      },
      {
        "isCorrect": false,
        "reason": "because for a continuous positively skewed unimodal distribution, the mode is less than the median, which is less than the mean."
      }
    ],
    "note": "Quantitative Methods: interpret and evaluate measures of skewness and kurtosis to address an investment problem"
  },
  {
    "id": "QUA-22",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the term Big Data has been in use since the late 1990s and refers to the vast amount of data being generated by industry, governments, individuals, and electronic devices. The term fintech is much broader."
      },
      {
        "isCorrect": false,
        "reason": "because automated trading, not fintech, refers to executing investment decisions through computer algorithms or automated trading applications. The term fintech is much broader."
      },
      {
        "isCorrect": true,
        "reason": "because in its broadest sense, the term 'fintech' generally refers to technology - driven innovation occurring in the financial services industry. For the purposes of this reading, fintech refers to technological innovation in the design and delivery of financial services and products. Note, however, that in common usage, fintech can also refer to companies (often new, startup companies) involved in developing the new technologies and their applications, as well as the business sector that comprises such companies."
      }
    ],
    "note": "Quantitative Methods: describe aspects of \"fintech\" that are directly relevant for the gathering and analyzing of financial data."
  },
  {
    "id": "QUA-23",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is the F - statistic calculated as MSR/MSE, 25/10 = 2.5. For a simple linear regression, the F - Statistic is MSR divided by MSE, where the mean square regression (MSR) is the same as the sum of squares regression [SSR] and the mean square error (MSE) is calculated as the sum of squares error (SSE) adjusted by its degrees of freedom, SSE / (n - 2); 280/(30 - 2)= 10."
      },
      {
        "isCorrect": true,
        "reason": "because it is the standard error of the estimate calculated as the square root of the mean square error, (10)0.5=3.2. The mean square error (MSE) is calculated as SSE/(n - 2): 280/(30 - 2)= 10.0, where SSE is the sum of squares error."
      },
      {
        "isCorrect": false,
        "reason": "because it is the mean square error (MSE) calculated as SSE / (n - 2), where SSE is the sum of squares error, 280/(30 - 2)=10.0."
      }
    ],
    "note": "Quantitative Methods: describe the use of analysis of variance (ANOVA) in regression analysis, interpret ANOVA results, and calculate and interpret the standard error of estimate in a simple linear regression"
  },
  {
    "id": "QUA-24",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because in bootstrap, we repeatedly draw samples from the original sample, and each resample is of the same size as the original sample. Note that each item drawn is replaced for the next draw (i.e., the identical element is put back into the group so that it can be drawn more than once) Assuming we are looking to find the standard error of sample mean, we take many resamples and then compute the mean of each resample."
      },
      {
        "isCorrect": false,
        "reason": "because in cluster sampling, elements are selected from the population not an original sample. The population is divided into clusters, each of which is essentially a mini - representation of the entire populations. Then certain clusters are chosen as a whole using simple random sampling."
      },
      {
        "isCorrect": false,
        "reason": "because in convenience sampling, elements are selected from the population not from an original sample. An element is selected from the population based on whether or not it is accessible to a researcher or on how easy it is for a researcher to access the element. Because the samples are selected conveniently, they are not necessarily representative of the entire population, and hence the level of the sampling accuracy could be limited."
      }
    ],
    "note": "Quantitative Methods: describe the use of bootstrap resampling in conducting a simulation based on observed data in investment applications"
  },
  {
    "id": "QUA-25",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because interest rates can be considered opportunity costs. The real risk - free interest rate is the single - period interest rate for a completely risk - free security if no\ninflation were expected. In economic theory, the real risk - free rate reflects the time preferences of individuals for current versus future real consumption. The sum of the real risk - free interest rate and the inflation premium is the nominal risk - free interest rate. As the inflation premium is 2%, the 1% real risk - free rate is not the opportunity cost of buying the US T - bill."
      },
      {
        "isCorrect": false,
        "reason": "because interest rates can be considered opportunity costs. The inflation premium compensates investors for expected inflation. The real risk - free interest rate is the single - period interest rate for a completely risk - free security if no inflation were expected. In economic theory, the real risk - free rate reflects the time preferences of individuals for current versus future real consumption. The sum of the real risk - free interest rate and the inflation premium is the nominal risk - free interest rate. As the real risk - free rate is 1%, the 2% inflation premium is not the opportunity cost of buying the US T - bill."
      },
      {
        "isCorrect": true,
        "reason": "because interest rates can be considered opportunity costs. The real risk - free interest rate is the single - period interest rate for a completely risk - free security if no inflation were expected. In economic theory, the real risk - free rate reflects the time preferences of individuals for current versus future real consumption. The sum of the real risk - free interest rate and the inflation premium is the nominal risk - free interest rate. Many countries have governmental short - term debt whose interest rate can be considered to represent the nominal risk - free interest rate in that country. The interest rate on a 90 - day US Treasury bill (T - bill), for example, represents the nominal risk - free interest rate over that time horizon. Therefore, the opportunity cost of this investment is 1% + 2% = 3%."
      }
    ],
    "note": "Quantitative Methods: interpret interest rates as required rates of return, discount rates, or opportunity costs and explain an interest rate as the sum of a real risk - free rate and premiums that compensate investors for bearing distinct types of risk"
  },
  {
    "id": "QUA-26",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is the money - weighted return when the dividend is reinvested. Calculator Solution: CF0 = - 100, CF1 = 0, CF2 = 109, compute IRR = 4.403% ~ 4.4%. The answer is also the geometric mean return; [(1 + 0.09)(1 + 0.00) ^0.5 - 1=0.04403 ~ 4.4%."
      },
      {
        "isCorrect": false,
        "reason": "because it is the arithmetic mean return; (0.09 + 0.00)/2 = 0.045 = 4.5%. The arithmetic or mean return is denoted by R, and given by the following equation for asset i, where R, is the return in period t and T is the total number of periods: R= (R/ + R/2 + ... + R)/T. The returns in Year 1 and Year 2 are calculated as (100 - 100 + 9)/100 = 0.09 and (100 - 100 + 0)/100 = 0.00, respectively."
      },
      {
        "isCorrect": true,
        "reason": "because it is the money - weighted return when the dividend is not reinvested. Calculator Solution: CF0 = - 100, CF1 = 9, CF2 = 100, compute IRR = 4.601% ~4.6%."
      }
    ],
    "note": "Quantitative Methods: compare the money - weighted and time - weighted rates of return and evaluate the performance of portfolios based on these measures"
  },
  {
    "id": "QUA-27",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because in regression analysis, we can use an F - distributed test statistic to test whether the slopes in a regression are equal to zero, with the slopes designated as b, against the alternative hypothesis that at least one slope is not equal to zero for simple linear regression, these hypotheses simplify to H0: b1 = 0. Ha bâ‚ â‰ 0."
      },
      {
        "isCorrect": false,
        "reason": "because in regression analysis, we can use an F - distributed test statistic to test whether the slopes in a regression are equal to zero, with the slopes designated as b, against the alternative hypothesis that at least one slope is not equal to zero for simple linear regression, these hypotheses simplify to H0 bâ‚ = 0. Ha bâ‚ â‰ 0."
      },
      {
        "isCorrect": false,
        "reason": "because in regression analysis, we can use an F - distributed test statistic to test whether the slopes in a regression are equal to zero, with the slopes designated as b, against the alternative hypothesis that at least one slope is not equal to zero for simple linear regression, these hypotheses simplify to H, bâ‚ = 0. Ha bâ‚ â‰  0."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret measures of fit and formulate and evaluate tests of fit and of regression coefficients in a simple linear regression"
  },
  {
    "id": "QUA-28",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because a tree - map is a graphical tool to display categorical data. It consists of a set of colored rectangles to represent distinct groups, and the area of each rectangle is proportional to the value of the corresponding group. Additional dimensions of categorical data can be displayed by nested rectangles."
      },
      {
        "isCorrect": true,
        "reason": "because probabilities for different scenarios and different outcomes are best represented using a tree diagram,"
      },
      {
        "isCorrect": false,
        "reason": "because the probability estimates are for two discrete random variables, not one continuous random variable. A probability function specifies the probability that the random variable takes on a specific value. For continuous random variables, the probability function is called the probability density function (pdf), or just the density."
      }
    ],
    "note": "Quantitative Methods: formulate an investment problem as a probability tree and explain the use of conditional expectations in investment application"
  },
  {
    "id": "QUA-29",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because tokenization is the process of representing ownership rights to physical assets on a blockchain or distributed ledger. It is not able to detect shifts in an analyst's sentiment."
      },
      {
        "isCorrect": false,
        "reason": "because data curation refers to the process of ensuring data quality and accuracy through a data cleaning exercise. This process consists of reviewing all data to detect and uncover data errors - bad or inaccurate data - and making adjustments for missing data when appropriate. While the data used for natural language processing may need to be curated, it is not, in of itself, able to detect shifts in an analyst's sentiment."
      },
      {
        "isCorrect": true,
        "reason": "because NLP [natural language processing] may be used to monitor analyst commentary to aid investment decision making. Since analysts tend not to change their buy, hold, and sell recommendations for a company frequently, they may instead offer nuanced commentary without making a change in their investment recommendation. NLP can, therefore, be used to detect, monitor, and tag shifts in sentiment, potentially ahead of an analyst's recommendation change."
      }
    ],
    "note": "Quantitative Methods: describe applications of Big Data and Data Science to investment management"
  },
  {
    "id": "QUA-30",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because a tree - map is useful for displaying a frequency distribution, not correlation. In addition to bar charts and grouped bar charts, another graphical tool for displaying categorical data is a tree - map. It consists of a set of colored rectangles to represent distinct groups, and the area of each rectangle is proportional to the value of the corresponding group. The tree - map can represent data with additional dimensions by displaying a set of nested rectangles."
      },
      {
        "isCorrect": true,
        "reason": "because scatter plots are a very useful tool for the sensible interpretation of a correlation coefficient. A scatter plot is a type of graph for visualizing the joint variation in two numerical variables. It is a useful tool for displaying and understanding potential relationships between the variables."
      },
      {
        "isCorrect": false,
        "reason": "because a clustered bar chart is useful for displaying a frequency distribution, not correlation. In the case of two categorical variables, we need an enhanced version of the bar chart, called a grouped bar chart (also known as a clustered bar chart), to show joint frequencies."
      }
    ],
    "note": "Quantitative Methods: interpret correlation between two variables to address an investment problem"
  },
  {
    "id": "QUA-31",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because Option 3 (annuity due with 20 payments of $13,000 each) has the highest present value of $137,847. The PV of Option 1 is $136,000.\nIf a candidate incorrectly calculated the present value of Option 3 as an ordinary annuity, the lump sum of $136,000 would have the highest present value. Incorrect calculator solution for Option 3: End mode; N = 20; I/Y = 8; PMT= - 13,000, compute PV = 127,636"
      },
      {
        "isCorrect": false,
        "reason": "because Option 3 (annuity due with 20 payments of $13,000 each) has the highest present value of $137,847. The PV of Option 2 is $135,093.\nIf a candidate ignored the discount rate, the option with the 30 payments of $12,000 each would have the highest value. That is, Option 2's 30 payments of $12,000 for a total of $360,000 is larger than Option 3's 20 payments of $13,000 for a total of $260,000 and the lump sum payment of $136,000."
      },
      {
        "isCorrect": true,
        "reason": "because Option 3 (annuity due with 20 payments of $13,000 each) has the highest present value of the annuities and the $136,000 lump sum."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the present value (PV) of fixed - income and equity instruments based on expected future cash flows"
  },
  {
    "id": "QUA-32",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because mean - variance analysis generally considers risk symmetrically in the sense that standard deviation captures variability both above and below the mean. An alternative approach evaluates only downside risk. We discuss one such approach, safety - first rules, as it provides an excellent illustration of the application of normal distribution theory to practical investment problems. Safety - first rules focus on shortfall risk, the risk that portfolio value will fall below some minimum acceptable level over some time horizon. Roy's safety - first criterion states that the optimal portfolio minimizes the probability that portfolio return, R, falls below the threshold level, R"
      },
      {
        "isCorrect": false,
        "reason": "because the safety - first ratio uses standard deviation, not semideviation, as a risk measure. The safety - first optimal portfolio maximizes the safety - first ratio (SFRatio):\nSFRatio = [E(RP) â€“ RL]/Ïƒp. The quantity E(RP) â€“ RL is the distance from the mean return to the shortfall level. Dividing this distance by op gives the distance in units of standard deviation. Although not used in Roy's safety - first criterion, semivariance, semideviation, and related dispersion measures [also] focus on downside risk. Semivariance is defined as the average squared deviation below the mean. Semideviation (sometimes called semistandard deviation) is the positive square root of semivariance."
      },
      {
        "isCorrect": false,
        "reason": "because Roy's safety - first criterion assumes that portfolio returns are normally distributed. If returns are normally distributed, the safety - first optimal portfolio maximizes\nthe safety - first ratio (SFRatio): SFRatio = [E(RP) â€“ R]/Ïƒp. The normal distribution, however, is less suitable as a model for asset prices than as a model for returns. A normal random variable has no lower limit. This characteristic has several implications for investment applications. An asset price can drop only to 0, at which point the asset becomes worthless.\nAs a result, practitioners generally do not use the normal distribution to model the distribution of asset prices."
      }
    ],
    "note": "Quantitative Methods: define shortfall risk, calculate the safety - first ratio, and identify an optimal portfolio using Roy's safety - first criterion"
  },
  {
    "id": "QUA-33",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because probability sampling gives every member of the population an equal chance of being selected. Hence it can create a sample that is representative of the population. In contrast, non - probability sampling depends on factors other than probability considerations, such as a sampler's judgment or the convenience to access data. Consequently there is a significant risk that non - probability sampling might generate a non - representative sample. In general, all else being equal, probability sampling can yield more accuracy and reliability compared with non - probability sampling."
      },
      {
        "isCorrect": false,
        "reason": "because probability sampling gives every member of the population an equal change of being selected. Hence it can create a sample that is representative of the population. In contrast, non - probability sampling depends on factors other than probability considerations, such as a sampler's judgment or the convenience to access data. Consequently there is a significant risk that non - probability sampling might generate a non - representative sample. In general, all else being equal, probability sampling can yield more accuracy and reliability compared with non - probability sampling."
      },
      {
        "isCorrect": true,
        "reason": "because probability sampling gives every member of the population an equal change of being selected. Hence it can create a sample that is representative of the population. In contrast, non - probability sampling depends on factors other than probability considerations, such as a sampler's judgment or the convenience to access data. Consequently there is a significant risk that non - probability sampling might generate a non - representative sample. In general, all else being equal, probability sampling can yield more accuracy and reliability compared with non - probability sampling."
      }
    ],
    "note": "Quantitative Methods: compare and contrast simple random, stratified random, cluster, convenience, and judgmental sampling and their implications for sampling error in an investment problem"
  },
  {
    "id": "QUA-34",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the t - statistic for a paired comparisons test has n - 1 degrees of freedom, not n - 2 degrees of freedom, where n is the number of pairs of observations. When n = 30, the number of degrees of freedom is 30 - 1=29, not 30 - 2=28."
      },
      {
        "isCorrect": true,
        "reason": "because the t - statistic for a paired comparisons test has n - 1 degrees of freedom, where n is the number of pairs of observations. When n = 30, the number of degrees of freedom is 30 - 1=29."
      },
      {
        "isCorrect": false,
        "reason": "because this is the number of degrees of freedom of the t - statistic for a hypothesis test concerning the equality of the population means of two independent samples, which is n1 + nâ‚‚ - 2. When both n1 and nâ‚‚ is 30, the number of degrees of freedom of the t - statistic for a hypothesis test concerning the equality of the population means of two independent samples is 30 + 30 - 2=58."
      }
    ],
    "note": "Quantitative Methods: construct hypothesis tests and determine their statistical significance, the associated Type I and Type II errors. and power of the test given a significance level"
  },
  {
    "id": "QUA-35",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is the difference between the third quartile and the second quartile, Q3 - Q2 = 93 - 62 = 31. The interquartile range (IQR) is the difference between the third quartile and the first quartile."
      },
      {
        "isCorrect": true,
        "reason": "because the interquartile range (IQR) is the difference between the third quartile, or IQR = and the first quartile, Q3 - Q1 \" = 93 â€“ 11 = 82. Quartiles divide the distribution into quarters."
      },
      {
        "isCorrect": false,
        "reason": "because it is the range of the four numbers given, and not the interquartile range. Q4 â€“ Q1 = 359 - 11 = 348"
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of central tendency and location to address an investment problem"
  },
  {
    "id": "QUA-36",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the p - value is the smallest level of significance at which the null hypothesis can be rejected."
      },
      {
        "isCorrect": true,
        "reason": "because the power of a test is the probability of Correctly rejecting the null - that is, the probability of rejecting the null when it is false."
      },
      {
        "isCorrect": false,
        "reason": "because the significance level of a test is the probability of rejecting a true null hypothesis (l.e., the probability of incorrectly rejecting a null hypothesis)."
      }
    ],
    "note": "Quantitative Methods: explain hypothesis testing and its components, including statistical significance, Type I and Type II errors, and the power of a test."
  },
  {
    "id": "QUA-37",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is the money - weighted rate of return of the investment. The money - weighted return and its calculation are similar to the internal rate of return. The internal rate of return is the discount rate at which the sum of present values of these cash flows will equal zero.\nCalculator solution.: [CF0] = investment in the first share= - 100, [CF1] = investment in the second share + dividend from first share = - 110 + 10 = - 100. [CF2] = proceeds of selling two shares = 230, [IRR] [CPT] = 0.09687 ~ 9.7%."
      },
      {
        "isCorrect": true,
        "reason": "because the time - weighted rate of return measures the compound rate of growth of $1 initially invested in the portfolio over a stated measurement period.... We find this time - weighted return by taking the geometric mean of the two holding period returns. A holding period return is the return earned from holding an asset for a single specified period of time.... This return can be generalized and shown as a mathematical expression in which P is the price and / is the income: R= [(P1 - Po) + I1]/Po. The subscript indicates the time of the price or income, (t = 0), is the beginning of the period and (t = 1) is the end of the period. Thus, the holding period return between time 0 and 1 is\nHPR1, = [(110 - 100) + 10]/100 = 0.2 = 20%,\nand the holding period return between time 1 and 2 is\nHPRâ‚‚ = [(230 - 220) + 0/220 = 0.04545~4.5%, where 220 = 110 x 2 is the price (value) of the two shares held by the investor at time 1.\nThe time - weighted rate of return is then [(1 + HPRâ‚) Ã— (1 + HPRâ‚‚)10.5 - 1 = [(1 + 0.2) Ã— (1 + 0.04545)]0.5 - 1=0.12006 ~ 12.0%."
      },
      {
        "isCorrect": false,
        "reason": "because it simply calculates the arithmetic average of the two holding period returns; (20% + 4.545%)/2= 12.273% ~12.3%."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret major return measures and describe their appropriate uses"
  },
  {
    "id": "QUA-38",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the second decile includes observations that are above the 10th percentile and at or below the 20th percentile. The 19th observation is in the second group of ten observations, but it is not in the second decile because there are only 75 observations in the sample."
      },
      {
        "isCorrect": true,
        "reason": "because the 19th observation is located at the 25th percentile\nLy = (1 + ð‘›) (\nð‘¦\n100)\n19 = (1 + 75)(\nð‘¦\n100); y = (\n19Ã—100\n1 + 75 ) = 25.0\n,which is in the second quintile. The second quintile includes observations that are above the 20th percentile and at or below the 40th percentile."
      },
      {
        "isCorrect": false,
        "reason": "because the second quartile includes observations that are above the 25th percentile and at or below the 50th percentile. Because the 19th observation is at the 25th percentile, it is in the first quartile."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of central tendency and location to address an investment problem"
  },
  {
    "id": "QUA-39",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because for a given dataset with different observations, the harmonic mean has the smallest value among harmonic, geometric, and arithmetic means. Unless all the observations in a dataset have the same value, the harmonic mean is less than the geometric mean, which, in turn, is less than the arithmetic mean."
      },
      {
        "isCorrect": true,
        "reason": "because the arithmetic mean of a given dataset with different observations is higher than the harmonic and geometric means. Unless all the observations in a dataset have the same value, the harmonic mean is less than the geometric mean, which, in turn, is less than the arithmetic mean"
      },
      {
        "isCorrect": false,
        "reason": "because for a given dataset with different observations, the geometric mean is larger than the harmonic mean but smaller than the arithmetic mean. Unless all the observations in a dataset have the same value, the harmonic mean is less than the geometric mean, which, in turn, is less than the arithmetic mean."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret different approaches to return measurement over time and describe their appropriate uses"
  },
  {
    "id": "QUA-40",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because sampling error is the difference between the observed value of a statistic and the quantity it is intended to estimate."
      },
      {
        "isCorrect": false,
        "reason": "because sampling error is the difference between the observed value of a statistic and the quantity it is intended to estimate."
      },
      {
        "isCorrect": true,
        "reason": "because sampling error is the difference between the observed value of a statistic and the quantity it is intended to estimate."
      }
    ],
    "note": "Quantitative Methods: compare and contrast simple random, stratified random, cluster, convenience, and judgmental sampling and their implications for sampling error in an investment problem"
  },
  {
    "id": "QUA-41",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the central limit theorem allows us to make quite precise probability statements about the population mean by using the sample mean, whatever the distribution of the population (so long as it has finite variance), because the sample mean follows an approximate normal distribution for large - size samples. Therefore, having a normally distributed population is not a requirement for the central limit theorem to hold."
      },
      {
        "isCorrect": true,
        "reason": "because the central limit theorem states that the variance of the distribution of the sample mean is ÏƒÂ²/n. The positive square root of variance is standard deviation. The standard deviation of a sample statistic is known as the standard error of the statistic. The sample mean, in addition to being an efficient estimator, is also a consistent estimator of the population mean: As sample size n goes to infinity, its standard error, olin, goes to 0 and its sampling distribution becomes concentrated right over the value of population mean, Î¼."
      },
      {
        "isCorrect": false,
        "reason": "because the central limit theorem states that the sum (and mean) [not the product] of a large number of independent random variables is approximately normally distributed."
      }
    ],
    "note": "Quantitative Methods: explain the central limit theorem and its importance for the distribution and standard error of the sample mean"
  },
  {
    "id": "QUA-42",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the variance of a random variable is the expected value (the probability - weighted average) of squared deviations from the random variable's expected value: oÂ²(X) = E[X - E(X)]. Since each scenario is equally likely (probability = 1/3), E(X) = (2.0 + 2.2 + 2.4)/3 = 2.2, so ÏƒÂ²(X) = [(2.0 - 2.2)Â² + (2.2 - 2.2)Â² + (2.4 - 2.2)2]/3 = [0.04 + 0.04]/3 = 0.08/3 = 0.0267 ~ 0.03 [in $2]"
      },
      {
        "isCorrect": false,
        "reason": "because it is the standard deviation, not the variance. The variance of a random variable is the expected value (the probability - weighted average) of squared deviations from the random variable's expected value: Ïƒ2(X) = E[X - E(X)]2. Since each scenario is equally likely (probability = 1/3), E(X) = (2.0 + 2.2 + 2.4)/3 = 2.2, so Ïƒ 2(X)= [(2.0 - 2.2)2 + (2.2 - 2.2)2 + (2.4 - 2.2)2]/3 = [0.04 + 0.04]/3 = 0.08/3 = 0.0267 [in $2]. Standard deviation is the positive square root of variance. Therefore, Ïƒ(X) = (0.0267)0.5= 0.1633 0.16 [in $]"
      },
      {
        "isCorrect": false,
        "reason": "because it is the difference between each pair of EPS values, not the variance: $2.40 - $2.20 =$2.20 - $2.00 = $0.20."
      }
    ],
    "note": "Quantitative Methods: calculate expected values, variances, and standard deviations and demonstrate their application to investment"
  },
  {
    "id": "QUA-43",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the 50th percentile is the median, which is the average of the two middle items. (Â£0.50 + Â£2.50)/2 = Â£1.50. In an odd - numbered sample of n items, the median occupies the (n + 1)/2 position. In an even - numbered sample, we define the median as the mean of the values of items occupying the n/2 and (n + 2)/2 positions (the two middle items). Calculating the median may also be more complex, to do so, we need to order the observations from smallest to largest, determine whether the sample size is even or odd and, on that basis, apply one of two calculations. Alternatively, the 50th percentile when Ly, is not a whole number or integer, Ly, lies between the two closest integer numbers\n(one above and one below), and we use linear interpolation between those two places to determine P. That is, L, = (n + 1)(y/100) = (4 + 1)(50/100) = 2.5. Hence, 2 is the closest integer below the calculated location and 3 is the closest integer above the calculated location. Using linear Interpolation, P0 = Â£0.50 + (Â£2.50 - Â£0.50) x (2.5 - 2) = Â£1.50,"
      },
      {
        "isCorrect": false,
        "reason": "because it is the location of the median; n/2 = 4/2. Alternatively, it is also the average EPS; ( - Â£0.50 + Â£0.50 + Â£2.50 + Â£5.50)/4= Â£2.00."
      },
      {
        "isCorrect": false,
        "reason": "because it is the position (or location) of the 50th percentile instead of the 50th percentile: (4 + 1) x 50/100 = 2.5. The formula for the position (or location) of a percentile in an array with n entries sorted in ascending order is L, = (n + 1)(y/100) where y is the percentage point at which we are dividing the distribution and L, is the location (L) of the percentile (P) in the array sorted in ascending order. The value of L, may or may not be a whole number. When L, is not a whole number or integer, L, lies between the two closest integer numbers (one above and one below), and we use linear interpolation between those two places to determine Py"
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of central tendency and location to address an investment problem"
  },
  {
    "id": "QUA-44",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because unlike the coefficient of determination and the F - statistic, which are relative measures of fit, the standard error of the estimate is an absolute measure of the distance of the observed dependent variable from the regression line."
      },
      {
        "isCorrect": false,
        "reason": "because it is the coefficient of determination, and not the standard error of estimate. The coefficient of determination, also referred to as the R - squared or RÂ², is the percentage of the variation of the dependent variable that is explained by the independent variable."
      },
      {
        "isCorrect": true,
        "reason": "because the standard error of the estimate is a measure of the distance between the observed values of the dependent variable and those predicted from the estimated regression."
      }
    ],
    "note": "Quantitative Methods: describe the use of analysis of variance (ANOVA) in regression analysis, interpret ANOVA results, and calculate and interpret the standard error of estimate in a simple linear regression"
  },
  {
    "id": "QUA-45",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because n (5) is used in the calculation instead of n - 1: (14/5)0.5, resulting in 1.67% ~1.7%."
      },
      {
        "isCorrect": true,
        "reason": "because the formula for target downside deviation is [E(X, - B)/(n - 1)]0.5, where X, is the return for the period, B is the target return and n is the total number of sample\nobservations. Moreover, the summation is taken over only those observations (X) that are less than or equal to the target B.\nYear Return (%) Deviations from the target Squared deviations\n1 6 0 0\n2 7 0 0\n3 3 - 2 4\n4 2 - 3 9\n5 4 - 1 1\nSince the sum of squared deviations is 14, the target downside deviation = [14/(5 - 1)]0.5, resulting in 1.87% ~ 1.9%."
      },
      {
        "isCorrect": false,
        "reason": "because all the returns are used in the calculation, not just the returns below the target. In other words, the standard deviation from the target return is calculated. Since the sum of all squared deviations is 14 + 5= 19, the target downside deviation is calculated as: [19/(5 - 1)]0.5 resulting in 2.18% ~ 2.2%.\nThis answer is also closest if n is assumed to be the number of observations used in the correct calculation (3): (14/3)0.5, resulting in 2.16% ~ 2.2%."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of dispersion to address an investment problem"
  },
  {
    "id": "QUA-46",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the Sharpe ratio is the average return in excess of the risk - free rate divided by the standard deviation of returns. This ratio measures the excess return earned per unit of standard deviation of return. Therefore, the Sharpe ratio does not quantify the amount of risk per unit of mean return."
      },
      {
        "isCorrect": false,
        "reason": "because the standard deviation measures risk, but it does not quantify the amount of risk per unit of mean return. Variance is defined as the average of the squared deviations around the mean. Standard deviation is the positive square root of the variance."
      },
      {
        "isCorrect": true,
        "reason": "because the coefficient of variation, CV, is the ratio of the standard deviation of a set of observations to their mean value. When the observations are returns, for example, the coefficient of variation measures the amount of risk (standard deviation) per unit of mean return."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of dispersion to address an investment problem"
  },
  {
    "id": "QUA-47",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it confuses the location of the second quartile, which is calculated as L, = (7 + 1) x 50/100 = 4, with the value of the second quartile, which is the return of the 4th fund after placing the funds' returns in ascending order. 4% also corresponds to the retum of the 4 fund (the middle fund) when the array has not been sorted in ascending order, which a candidate might interpret as the 50th percentile (the median)."
      },
      {
        "isCorrect": true,
        "reason": "because the formula for the position of a percentile in an array with n entries sorted in ascending order is L = (n + 1) x Y/100, where y is the percentage point at which we are dividing the distributien and L, is the location (L) of the percentile (P) in the array sorted in ascending order with seven entries, the location of the second quartile, or 50th percentile, is: L= (7 + 1) x 50/100 = 4 When placing the funds' returns in ascending order (3%, 3%, 4%, 5% 7%, 8%; 12%), the return of the 4th fund is 5%\nAlteratively, candidates might realize that the secced quartile or 50th percentue is the median, The median is the value of the middle item of a set of items that has been sorted into ascending or descending order. In an odd - numbered sample of n items, the median occupies the (n + 1)/2 position Hence, the median return is 5%."
      },
      {
        "isCorrect": false,
        "reason": "because the mean is mistaken as the 50th percentile or second quartile, mean return = (12% + 8% + 7% + 5% + 4% + 3% + 3% )/7=6%."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of central tendency and location to address an investment problem"
  },
  {
    "id": "QUA-48",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because correlation ranges from - 1 and + 1 for two random variables, X and Y"
      },
      {
        "isCorrect": false,
        "reason": "because correlation may also be an unreliable measure when outliers are present in one or both of the variables. As we have seen, outliers are small numbers of observations at either extreme (small or large) of a sample. The correlation may be quite sensitive to outliers"
      },
      {
        "isCorrect": true,
        "reason": "because the correlation coefficient expresses the strength of the linear relationship between the two random variables."
      }
    ],
    "note": "Quantitative Methods: interpret correlation between two variables to address an investment problem"
  },
  {
    "id": "QUA-49",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the correlation between two random variables, R, and R,, is defined as p(Ri,Rj)= Cov(Ri,Rj), [o(Ri),Ïƒ(Rj)], where Cov denotes the covariance and Ïƒ the standard\ndeviation. Since the standard deviation of each asset occurs in the denominator of the correlation formula, it is clear that, all else being equal. an increase in the variance (hence standard deviation) of either variable will decrease the correlation."
      },
      {
        "isCorrect": false,
        "reason": "because the correlation between two random variables, R, and R, is defined as p(Ri,Rj) = Cov(Ri,Rj)[ Ïƒ(Ri), Ïƒ(Rj)], where Cov denotes the covariance and Ïƒ the standard deviation. Hence an increase in variance will decrease the correlation, not keep it the same. Candidates may select this answer choice since the covariance of correlated variables has remained the same, or if they assume that correlation is independent of variance."
      },
      {
        "isCorrect": false,
        "reason": "because the correlation between two random variables, R, and R, is defined as p(Ri,Rj) = Cov(Ri,Rj /[ Ïƒ (Ri),Ïƒ(Rj)], where Cov denotes the covariance and Ïƒ the standard deviation. Hence an increase in variance will decrease the correlation, not increase it. Candidates may select this answer choice if they think that more variance means more covariance and hence more correlation, or if they swap numerator and denominator of the correlation formula; [Ïƒ(Ri),Ïƒ(Rj)]/Cov(Ri,Rj)."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the expected value, variance, standard deviation, covariances, and correlations of portfolio returns"
  },
  {
    "id": "QUA-50",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the correlation coefficient is a measure of the linear association between two variables; it would not be appropriate to use the correlation coefficient to measure the non - linear relationship between variables"
      },
      {
        "isCorrect": false,
        "reason": "because the correlation coefficient is a measure of the linear association between two variables. It does not measure non - linear relationships between variables."
      },
      {
        "isCorrect": false,
        "reason": "because the correlation coefficient is a measure of the linear association between two variables. It does not measure non - linear relationships between variables."
      }
    ],
    "note": "Quantitative Methods: interpret correlation between two variables to address an investment problem"
  },
  {
    "id": "QUA-51",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the equation to estimate the standard error of the sample mean effectively computes the sample standard deviation of the different means generated across all resamples. Hence the mean of each resample is required. However, neither the mean, nor the standard deviation, of the original sample are required"
      },
      {
        "isCorrect": false,
        "reason": "because the equation to estimate the standard error of the sample mean effectively computes the sample standard deviation of the different means generated across all resamples. Hence the mean of each resample is required. However, neither the mean, nor the standard deviation, of the original sample are required."
      },
      {
        "isCorrect": false,
        "reason": "because the equation to estimate the standard error of the sample mean effectively computes the sample standard deviation of the different means generated across all resamples. Hence the mean of each resample is required. However, neither the mean, nor the standard deviation, of the original sample are required."
      }
    ],
    "note": "Quantitative Methods: describe the use of resampling (bootstrap, jackknife) to estimate the sampling distribution of a statistic"
  },
  {
    "id": "QUA-52",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the expected value E(X) = Î£i=1 nP(Xi)Xj = (0.20 x 35) + (0.30 x 50) + (0.50 x 80) = 62. The variance Ïƒ2(X) = E{[X - E(X)]2}= Î£i=1 nP(Xi)[X - E(X)]2 = 0.20 x (35 - 62)2 + 0.30 x (50 - 62)2 + 0.50 Ã— (80 - 62)2 = 351. Standard deviation is the positive square root of variance: Ïƒ = 3511/2 ~ 18.73."
      },
      {
        "isCorrect": false,
        "reason": "because it uses the simple average of the outcomes instead of the expected value in the calculation. The simple average Xbar = (35 + 50 + 80)/3 = 55. Hence the variance becomes Ïƒ2(X) = Î£i=1 nP(Xi)[X â€” Xbar]2 =0.20 x (35 - 55)2 + 0.30 x (50 - 55)2 + 0.50 x (80 - 55)2 = 400. Then, the standard deviation is equal to Ïƒ = 4001/2 = 20.00."
      },
      {
        "isCorrect": false,
        "reason": "because it ignores that this is a random variable and just calculates the sample standard deviation instead for a sample with 3 observations. The sample mean Xoar (35 + 50 + 80)/3 = 55. Hence the sample variance is equal to Ïƒ2 = (Î£i=1 n [X - Xbar]2)/(n âˆ’ 1) = [(35 âˆ’55)2 + (50 - 55)2 + (80 - 55)/(3 - 1) = 525. Then, the sample standard deviation is equal to Ïƒ = 5251/2 ~ 22.91."
      }
    ],
    "note": "Quantitative Methods: calculate expected values, variances, and standard deviations and demonstrate their application to investment problems"
  },
  {
    "id": "QUA-53",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it wrongly multiplies the expected dividend per share given the favorable scenario ($1.90) by the probability of the scenario (0.60):\nProbability of favorable scenario x E(Dividend | Favorable scenario)\n= 0.60 Ã— [(0.80 x $2.00) + (0.20 x $1.50)]\n= 0.60 x $1.90\n= $1.14."
      },
      {
        "isCorrect": false,
        "reason": "because it is the unconditional expected dividend per share based on the total probability rule for expected value:\nE(Dividend | Favorable scenario) = (0.80 x $2.00) + (0.20 x $1.50) = $1.90.\nE(Dividend | Unfavorable scenario) = (0.30 x $0.75) + (0.70 x $0.50) = $0.575.\nE(Dividend) = (0.60 x $1.90) + (0.40 x $0.575) = $1.37."
      },
      {
        "isCorrect": true,
        "reason": "because the expected value of a random variable X given an event or scenario S is denoted E(XS). Suppose the random variable X can take on any one of n distinct outcomes X1, X2, â€¦.Xn, (these outcomes form a set of mutually exclusive and exhaustive events). The expected value of X conditional on S is the first outcome, X,, times the probability of the first outcome given S, P(X1 | S), plus the second outcome, Xâ‚‚, times the probability of the second outcome given S, P(X2 | S), and so forth.\nIn our case,\nS = Favorable scenario,\nX1 = Dividend of $2.50, P(X1 | S) = 0.80\nXâ‚‚ = Dividend of $1.50, P(Xâ‚‚ | S) = 0.20.\nThus, the expected dividend given the favorable scenario = (0.80 x $2.00) + (0.20 x $1.50) = $1.90."
      }
    ],
    "note": "Probability Trees and Conditional Expectations: formulate an investment problem as a probability tree and explain the use of conditional expectations in investment application"
  },
  {
    "id": "QUA-54",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it takes the natural logarithm of Term Deposit 1's stated annual rate instead of its effective annual rate (EAR). Calculation: In(1.04) = 0.039221 = 3.92%."
      },
      {
        "isCorrect": true,
        "reason": "because the investor will be indifferent if the EAR for both term deposits is the same. Therefore, we need to find the stated annual rate with continuous compounding that corresponds to the EAR of the quarterly compounded term deposit. Calculations: EAR of Term Deposit 1 = (1 + 0.04/4)4 - 1= 0.040604. Hence, EAR of Term Deposit 2 = 0.040604=er - 1, leading to a stated annual rate for Term Deposit 2 of r = In(1.040604) = 0.039801 = 3.98%."
      },
      {
        "isCorrect": false,
        "reason": "because it is the EAR of Term Deposit 1, not the stated annual rate of Term Deposit 2. EAR of Term Deposit 1 = (1 + 0.04/4)4 - 1= 0.040604 = 4.06%. This answer is also closest to the calculations e0.04 - 1 = 0.040811 = 4.08% or e0.040604 - 1 = 0.041440 = 4.14%.\n="
      }
    ],
    "note": "Quantitative Methods: calculate and interpret annualized return measures and continuously compounded returns, and describe their appropriate uses"
  },
  {
    "id": "QUA-55",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the harmonic mean is used to determine the average price paid per share when using cost averaging.\n3 1 14 + 1\n12 + 1\n17\n= 14.05\nThe weighted mean formula could also be used, where the weights would be the proportion of the total number of shares purchased. However, in order to use this method a fixed investment amount would need to be created."
      },
      {
        "isCorrect": false,
        "reason": "because it is the average price per share, not the cost per share; (14 + 12 + 17)/3 = 14.33. Using the arithmetic mean assumes equal weighting, which is not appropriate when the investment amount is fixed and the share price is variable."
      },
      {
        "isCorrect": false,
        "reason": "because the price per share is incorrectly used as the weight in the weighted mean formula:\n14(\n14\n14 + 12 + 17) + 12(\n12\n14 + 12 + 17) + 17(\n17\n14 + 12 + 17) = 14.63"
      }
    ],
    "note": "Quantitative Methods: calculate and interpret different approaches to return measurement over time and describe their appropriate uses"
  },
  {
    "id": "QUA-56",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because in the log - lin model, the dependent variable is in logarithmic form and the independent variable is not."
      },
      {
        "isCorrect": true,
        "reason": "because the lin - log model is similar to the log - lin model, but only the independent variable is in logarithmic form."
      },
      {
        "isCorrect": false,
        "reason": "because the log - log model is one in which both the dependent variable and the independent variable are linear in their logarithmic forms. In the lin - log model only the independent variable is in logarithmic form."
      }
    ],
    "note": "Quantitative Methods: describe different functional forms of simple linear regressions"
  },
  {
    "id": "QUA-57",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the covariance formula is misapplied as Cov(RA,RB) = Î£P(RA,i,RB,j)(RA,i âˆ’ E[RA]) + Î£P(RA,iâ€šRBi) (RB,i - E[RB]), resulting in 0.2(2014) + 0.4(1514) + 0.4(10 - 14) + 0.2(159) + 0.4(109) + 0.4(5 - 9) = 1.2 + 0.4 + ( - 1.6) + 1.2 + 0.4 + ( - 1.6) = 0."
      },
      {
        "isCorrect": false,
        "reason": "because the covariance formula is misapplied as Cov(RA,RB) = Î£P(RA,i,RB,i)(RA,i - RB,i;) resulting in\n0.2(20 - 15) + 0.4(15 - 10) + 0.4(10 - 5)\n= 0.2(5) + 0.4(5) + 0.4(5)\n= 1 + 2 + 2=5.\n14 - 9 = 5."
      },
      {
        "isCorrect": true,
        "reason": "because the formula for calculating the covariance between random variables RA, and RB is Cov(RA,RB) = Î£Î£P(RA,I,RB,i)(RA,i) - E[RA])(RB,j - E[RB]).\nThe expected return (given) for each company is:\nE[RX]= 0.2(20) + 0.4(15) + 0.4(10) = 4 + 6 + 4= 14,\nE[RY] = 0.2(15) + 0.4(10) + 0.4(5)=3 + 4 + 2 = 9.\nHence, Cov(Rx,Ry) = 0.2(2014) (15 - 9) + 0.4(15 - 14)(10 - 9) + 0.4(10 - 14)(5 - 9)=0.2(6)(6) + 0.4(1)(1) + 0.4( - 4) ( - 4)=7.2 + 0.4 + 6.4 = 14."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the covariance and correlation of portfolio returns using a joint probability function for returns"
  },
  {
    "id": "QUA-58",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the mean absolute deviation of 1.5% is less than the sample standard deviation of 1.83%. The mean absolute deviation, MAD, is calculated as:\nâˆ‘ |ð‘‹ð‘– âˆ’ð‘‹| ð‘› ð‘–=1\nð‘›\nwhere the sample mean,\nð‘‹Ì…=\nâˆ‘ ð‘‹ð‘– ð‘› ð‘–=1\nð‘›\nð‘‹Ì…=\n(âˆ’2âˆ’1 + 1 + 2)\n4 = 0\n|âˆ’2âˆ’0| + |âˆ’1âˆ’0| + |1âˆ’0| + |2âˆ’0|\n4 =\n2 + 2 + 1 + 1\n4\n= 1.5000%, while the sample standard deviation of n observations, Xi, is\nS = âˆšâˆ‘ (ð‘‹ð‘–âˆ’ð‘‹) ð‘› ð‘–=1 ^2\nð‘›âˆ’1\nâˆš(âˆ’2âˆ’0)2 + (âˆ’1âˆ’0)2 + (1âˆ’0)2 + (2âˆ’0)2\n4âˆ’1 = âˆš\n4 + 1 + 4 + 1\n3 = âˆš3.3333\n= 1.8257%."
      },
      {
        "isCorrect": false,
        "reason": "because the mean absolute deviation, MAD, is less than standard deviation of returns in the sample. The mean absolute deviation, MAD, is calculated as:\nâˆ‘ |ð‘‹ð‘–âˆ’ð‘‹| ð‘› ð‘–=1\nð‘›\nwhere the sample mean,\nð‘‹Ì…=\nâˆ‘ ð‘‹ð‘– ð‘› ð‘–=1\nð‘›\nwhich results in MAD = 1.50% while sample standard deviation\nS = âˆšâˆ‘ (ð‘‹ð‘–âˆ’ð‘‹) ð‘› ð‘–=1 ^2\nð‘›âˆ’1\n= 1.83% therefore MAD is less than standard deviation of sample returns."
      },
      {
        "isCorrect": false,
        "reason": "because the mean absolute deviation, MAD, is less than standard deviation of returns in the sample.\nThe mean absolute deviation, MAD, is calculated as:\nâˆ‘ |ð‘‹ð‘– ð‘› ð‘–=1 âˆ’ð‘‹Ì…| ð‘›\nwhere the sample mean,\nð‘‹Ì…=\nâˆ‘ ð‘‹ð‘– ð‘› ð‘–=1\nð‘›\nwhich results in MAD = 1.50% while sample standard deviation\nS = âˆšâˆ‘ (ð‘‹ð‘–âˆ’ð‘‹Ì…)2 ð‘› ð‘–=1\nð‘›âˆ’1\n= 1.83% therefore MAD is less than standard deviation of sample returns."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of dispersion to address an investment problem"
  },
  {
    "id": "QUA-59",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the money - weighted return and its calculation are similar to the internal rate of return and the yield to maturity. Just like the internal rate of return, amounts invested are cash outflows from the investor's perspective and amounts returned or withdrawn by the investor, or the money that remains at the end of an investment cycle, is a cash inflow for the investor. For the stock investment this is: $20 $3/(1 + r) + ($20 + $1)/(1 + r)Â², yielding r = 10.24% ~10%."
      },
      {
        "isCorrect": false,
        "reason": "because it is time - weighted, not money - weighted, rate of return. For the stock investment, the holding period returns (HPR) for the two periods are HPR, = ($12 - $20 + $3)/$20= - 0.25= - 25% and HPRâ‚‚ = ($20 - $12 + $1)/$12 = 0.75 = 75%. Hence, TWR = âˆš(0.75 x 1.75) - 1=0.1456 = 14.56% ~ 15%."
      },
      {
        "isCorrect": false,
        "reason": "because it confuses the money - weighted rate of return with the 'money returned', Le. the net cash flow: $20 + $3 + $1 - $20= $4, which, on an initial investment of $20, corresponds to a 20% return; $4/$20 = 0.2 = 20%."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret major return measures and describe their appropriate uses"
  },
  {
    "id": "QUA-60",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the money - weighted return and its calculation are similar to the internal rate of return and the yield to maturity. Just like the internal rate of return, amounts invested are cash outflows from the investor's perspective and amounts returned or withdrawn by the investor, or the money that remains at the end of an investment cycle, is a cash inflow for the investor That is, cash withdrawals and investments are included in the money - weighted return calculation, however, cash withdrawals and investments are ignored in the calculation of the arithmetic and geometric mean returns"
      },
      {
        "isCorrect": true,
        "reason": "because the money - weighted return is an accurate measure of what the investor actually eamed on the money invested"
      },
      {
        "isCorrect": false,
        "reason": "because although the money - weighted return is an accurate measure of what the investor actually earned on the money invested, it is limited in its applicability to other situations. For example, it does not allow for return comparison between different\nindividuals or different investment opportunities. Two investors in the same mutual fund may have different money - weighted returns because they invested different amounts in different years."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret major return measures and describe their appropriate uses"
  },
  {
    "id": "QUA-61",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because an investment measure that is not sensitive to the additions and withdrawals of funds is the time - weighted rate of return. The time - weighted rate of return measures the compound rate of growth of $1 initially invested in the portfolio over a stated measurement period. For the evaluation of portfolios of publicly traded securities, the time - weighted rate of return is the preferred performance measure as it neutralizes the effect of cash withdrawals or additions to the portfolio, which are generally outside of the control of the portfolio manager."
      },
      {
        "isCorrect": false,
        "reason": "because the simplest way to compute the return is to take a simple arithmetic average of all holding period returns. Moreover, the arithmetic mean return assumes that the amount invested at the beginning of each period is the same. Thus, the arithmetic mean return does not account for cash additions to the portfolio and it is not affected by them."
      },
      {
        "isCorrect": true,
        "reason": "because the money - weighted rate of return ... puts a greater weight on the second year's relatively poor performance... than the first year's relatively good performance..., as more money was invested in the second year than in the first. That is the sense in which returns in this method of calculating performance are 'money weighted If a client gives an investment manager more funds to invest at an unfavorable time, the manager's money - weighted rate of return will tend to be depressed."
      }
    ],
    "note": "Quantitative Methods: compare the money - weighted and time - weighted rates of return and evaluate the performance of portfolios based on these measures"
  },
  {
    "id": "QUA-62",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because \"uncorrelated\" is misinterpreted as having a correlation value of - 1 (i.e., perfect negative correlation is used instead of zero) when calculating the portfolio standard deviation;\nÏƒp =\nâˆš(0.5)Â²(3)Â² + (0.5)Â²(3)Â² + 2(0.5)(0.5)(3)(3)(âˆ’1) = âˆš0 = 0% -"
      },
      {
        "isCorrect": true,
        "reason": "because the portfolio standard deviation is 2.1%;\nâˆš(0.5)2(3)2 + (0.5)2(3)2 + 2(0.5)(0.5)(3)(3)(0) = âˆš4.5\nor 2.12%, using the formula\nâˆšÏƒ2p = âˆšw[Ww1 Ïƒ21 + W22 Ïƒ22 + 2W1W2Cov(R1,R2)\nwhere the Cov(R1,R2) = P(R1,R2)Ïƒ(R1)Ïƒ(R2)\n, which is equal to zero because the funds are uncorrelated;\nP(R1, R2)=0."
      },
      {
        "isCorrect": false,
        "reason": "because it is the weighted average of the two securities' standard deviation and calculates the portfolio standard deviation as: Ïƒ = (0.5) (3%) + (0.5) (3%) = 3.0%."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the expected value, variance, standard deviation, covariances, and correlations of portfolio retums"
  },
  {
    "id": "QUA-63",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the present value of the future lump sum payment is PV = FVN (1 + r) - N = $500,000(1 + 0.04) - 15= $277,632.25. The 10 annual payments form an annuity due (since the payments start today) whose present value equals the present value of an ordinary annuity with 9 annual payments plus the first payment, i.e. PV = A + A[1 - 1/(1 + r)N ]/r=A(1 + [1 - 1/(1 + 0.04)9]/0.04)= 8.4353 (A). Setting the PV of the cash outflows (the annuity) equal to the PV of the cash inflows (the return in 15 years), we can solve for the annual payment\namount; A = $277,632.25/8.4353 $32,913."
      },
      {
        "isCorrect": false,
        "reason": "because it mistakes the required payments as an ordinary annuity, rather than an annuity due, calculating their present value as: PV = A[1 - 1/(1 + r)N]/r = A([1 - 1/(1 + 0.04)10 ]/0.04)= 8.1109(A). The present value of the return at t = 15 is PV = FV (1 + r) - N= $500,000(1 + 0.04) - 15= $277,632.25. Setting these two values equal and solving for the annual payment thus yields: A = $277,632.25/8.1109 $34,230."
      },
      {
        "isCorrect": false,
        "reason": "because it assumes the $500,000 return is paid at t = 10 instead of t = 15. The present value of this payment is therefore PV = FV (1 + r) - N = $500,000(1 + 0.04) - 10 = $337,782.08. The 10 annual payments form an annuity due (since the payments start today) whose present value equals the present value of an ordinary annuity with 9 annual payments plus the first payment, i.e. PV = A + A[1 - 1/(1 + r)N ]/r=A(1 + [1 - 1/(1 + 0.04)9 /0.04)= 8.4353(A). Setting the PV of the cash outflows (the annuity) equal to the PV of the cash inflows (the return in 15 years), we can solve for the annual payment amount; A = $337,782/8.4353 ~ $40,044."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the implied return of fixed - income instruments and required return and implied growth of equity instruments given the present value (PV) and cash flows"
  },
  {
    "id": "QUA-64",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the power of the test is equal to one minus the probability of Type II error. The p - value is a measure of Type I error and is synonymous with distracter B."
      },
      {
        "isCorrect": false,
        "reason": "because the power of the test is equal to one minus the probability of Type II error. The p - value is a measure of Type I error and is synonymous with distracter B."
      },
      {
        "isCorrect": true,
        "reason": "because the power of a test is the probability of Correct ly rejecting the null - that is, the probability of rejecting the null when it is false. Failing to reject the null hypothesis when it is false is a Type II error. So the power of the test is equal to one minus the probability of Type II error."
      }
    ],
    "note": "Quantitative Methods: explain hypothesis testing and its components, including statistical significance, Type I and Type II errors, and the power of a test."
  },
  {
    "id": "QUA-65",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the prediction interval is equal to the predicted value of the dependent variable plus/minus the critical t - value times the standard error of the forecast. The larger the sample size (n) in the regression estimation, the smaller the standard error of the forecast. Meanwhile, when the sample size is larger, the critical t - value will be smaller. Both will lead to a narrower prediction interval if holding other things constant."
      },
      {
        "isCorrect": false,
        "reason": "because the prediction interval is equal to the predicted value of the dependent variable plus/minus the critical - value times the standard error of the forecast. When the level of significance increases, the critical - value will decrease, which will lead to a narrower prediction interval if holding other things constant."
      },
      {
        "isCorrect": true,
        "reason": "because the prediction interval is equal to the predicted value of the dependent variable plus/minus the critical ! - value times the standard error of the forecast. The better the fit of the regression model, the smaller the standard error of the estimate (s) and, therefore, the smaller standard error of the forecast. When the standard error of the estimate increases, the standard error of the forecast will increase, which will lead to a wider prediction interval if holding other things constant."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the predicted value for the dependent variable, and a prediction interval for it, given an estimated linear regression model and a value for the independent variable"
  },
  {
    "id": "QUA-66",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the annuity is taken as an ordinary annuity rather than an annuity due,\nleading to a PV 10 years from today of PV10 $50,000 x [1 - 1/(1.03)4]/0.03= $50,000 Ã—\n3.717098 = $185,855. The PV of the annuity today would equal PV, = $185.855/(1.03)^10 = $138,294."
      },
      {
        "isCorrect": true,
        "reason": "because the present value (PV) of the annuity due 10 years from today equals PV 10 = $50,000 + $50,000 [1 - 1/(1.03) ^3/0.03 =$50,000 + $50,000 x 2.828611 = $191,431. The PV of the annuity today equals PV $191.431/(1.03)^10 =$142,442.\nAlternatively, the annuity can be treated as an ordinary annuity, with a PV 9 years from today of PV,= $50,000 Ã— [1 - 1/(1.03)^4/0.03 = $50,000 Ã— 3.717098 = $185,855. The PV of the annuity today equals PVâ‚ = $185,855/(1.03)^9 = $142,442."
      },
      {
        "isCorrect": false,
        "reason": "because the PV of the annuity due is discounted back 9 years instead of 10 years: $191,431/(1.03)^9 = $146,716."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the implied return of fixed - income instruments and required return and implied growth of equity instruments given the present value (PV) and cash flows"
  },
  {
    "id": "QUA-67",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it assumes the ordinary annuity starts in Year 5 instead of Year 4. The present value of an ordinary annuity with 7 payments of $10,000 at a 6% discount rate is calculated as follows:\nPV=A[1 - 1/(1 + r)N]/r\nPV4=$10,000 Ã— [1 - 1/(1 + 0.06)7]/0.06\nPV4 $55,823.81\nPV1 = FV5(1 + r) - N\nPV= $55,823.81 Ã— (1 + 0.06) - 5\nPV= $41,714.80 ~ $41,715.\n(1) END mode; N = 7; 1= 6; PMT = - 10,000; FV = 0; solve for PV = 55,823.81.\n(2) END mode; N = 5; 1= 6; PMT = 0; FV = - 55,823.81; solve for PV = 41,714.80."
      },
      {
        "isCorrect": true,
        "reason": "because the present value in Year 4 of an ordinary annuity with 7 payments of $10,000 at a 6% discount rate is calculated as follows:\nPV=A[1 - 1/(1 + r)N]/r\nPV4 $10,000 Ã— [1 - 1/(1 + 0.06)7]/0.06\nPV4 $55,823.81\nThen, using a time line, the PV of the annuity in today's dollars is\nPV0 = FV4(1 + r) - N\nPV0 $55,823.81 Ã— (1 + 0.06) - 4\nPV0 $44,217.69 ~ $44,218.\n(1) END mode; N = 7; 1= 6; PMT= - 10,000; FV = 0; solve for PV = 55,823.81.\n(2) END mode; N = 4; 1= 6; PMT = 0; FV = - >55,823.81; solve for PV = 44,217.69."
      },
      {
        "isCorrect": false,
        "reason": "because it is an intermediate step in the calculation and it represents the value of the annuity in 4 years. The present value in Year 4 of an ordinary annuity with 7 payments of $10,000 at a 6% discount rate is calculated as follows:\nPV=A[1 - 1/(1 + r)^N/r\nPV, $10,000 x [1 - 1/(1 + 0.06)^7]/0.06\nPV $55,823.81 ~ $55,824."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret the present value (PV) of fixed - income and equity instruments based on expected future cash flows"
  },
  {
    "id": "QUA-68",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because we look at the sum of squared deviations of the observations from the mean to capture [the variation of the dependent variable]. Our goal is to understand what explains the variation of Y. The variation of Y is often referred to as the sum of squares total (SST), or the total sum of squares. Therefore, the difference between an observation and the mean of the dependent variable is not the observation's residual."
      },
      {
        "isCorrect": true,
        "reason": "because the residual for the observation, e,, is how much the observed value of Y, differs from the estimated [value] using the regression line. Further, the residual refers to the fitted linear relation based on the sample."
      },
      {
        "isCorrect": false,
        "reason": "because the error term refers to the true underlying population relationship, whereas the residual refers to the fitted linear relation based on the sample. Further, the error term, or simply the error, represents the difference between the observed value of Y and that expected from the true underlying population relation between Y and X"
      }
    ],
    "note": "Quantitative Methods: describe a simple linear regression model, how the least squares criterion is used to estimate regression coefficients, and the interpretation of these coefficients"
  },
  {
    "id": "QUA-69",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the liquidity premium compensates investors for the risk of loss relative to an investment's fair value if the investment needs to be converted to cash quickly. US T - bills, for example, do not bear a liquidity premium because large amounts can be bought and sold without affecting their market price."
      },
      {
        "isCorrect": false,
        "reason": "because the maturity premium compensates investors for the increased sensitivity of the market value of debt to a change in market interest rates as maturity is extended. For example, the difference between the interest rate on longer - maturity, liquid Treasury debt and that on short - term Treasury debt reflects a positive maturity premium for the longer - term debt."
      },
      {
        "isCorrect": true,
        "reason": "because the real risk - free rate reflects the time preferences of individuals for current versus future real consumption."
      }
    ],
    "note": "Quantitative Methods: interpret interest rates as required rates of return, discount rates, or opportunity costs and explain an interest rate as the sum of a real risk - free rate and premiums that compensate investors for bearing distinct types of risk"
  },
  {
    "id": "QUA-70",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the target downside deviation = [(X - B)(n - 1)]0.5, where X, are the periodic returns below the target return, B is the target return, and n is the total number of periods. Since the sample has a standard deviation of 2.7%, it will have values below and above its mean of 1.0%. Since the target downside deviation ignores the deviations above the mean, it will be less than the standard deviation."
      },
      {
        "isCorrect": false,
        "reason": "because the target downside deviation = [(X, - B)/(n - 1)], where X, are the periodic returns below the target return, B is the target return, and n is the total number of periods. Since the sample has a standard deviation of 2.7%, it will have values below and above its mean of 1.0%. Since the target downside deviation ignores the deviations above the mean, it will be less than the standard deviation."
      },
      {
        "isCorrect": false,
        "reason": "because the target downside deviation = [(X - B)/(n - 1)]0.5, where X, are the periodic returns below the target return, B is the target return, and n is the total number of periods. Since the sample has a standard deviation of 2.7%, it will have values below and above its mean of 1.0%. Since the target downside deviation ignores the deviations above the mean, it will be less than the standard deviation."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of dispersion to address an investment problem"
  },
  {
    "id": "QUA-71",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the trimmed mean is computed by excluding a stated small percentage of the lowest and highest values and then computing an arithmetic mean of the remaining values. For example, a 5% trimmed mean discards the lowest 2.5% and the highest 2.5% of values and computes the mean of the remaining 95% of values."
      },
      {
        "isCorrect": false,
        "reason": "because the harmonic mean is the value obtained by summing the reciprocals of the observations - terms of the form 1/X - then averaging that sum by dividing it by the number of observations n, and, finally, taking the reciprocal of the average. The harmonic mean may be viewed as a special type of weighted mean in which an observation's weight is inversely proportional to its magnitude. The harmonic mean does not exclude or replace any outliers."
      },
      {
        "isCorrect": false,
        "reason": "because the winsorized mean is calculated by assigning a stated percentage of the lowest values equal to one specified low value and a stated percentage of the highest values equal to one specified high value, and then it computes a mean from the restated data. For example, a 95% winsorized mean sets the bottom 2.5% of values equal to the value at or below which 2.5% of all the values lie (as will be seen shortly, this is called the '2.5th percentile' value) and the top 2.5% of values equal to the value at or below which 97.5% of all the values lie (the '97.5th percentile' value)."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of central tendency and location to address an investment problem"
  },
  {
    "id": "QUA-72",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the stock price will be distributed in a lognormal manner, not in a normal or uniform manner."
      },
      {
        "isCorrect": false,
        "reason": "because the stock price will be distributed in a lognormal manner, not in a normal or uniform manner."
      },
      {
        "isCorrect": true,
        "reason": "because the relationship between normal and lognormal distributions is if a stock's continuously compounded return is normally distributed, then future stock price is necessarily lognormally distributed."
      }
    ],
    "note": "Quantitative Methods: explain the relationship between normal and lognormal distributions and why the lognormal distribution is used to model asset prices when using continuously compounded asset returns"
  },
  {
    "id": "QUA-73",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the procedure does not involve the systematic selection of a sample from the population. With systematic sampling, we select every kth member until we have a sample of the desired size. The sample that results from this procedure should be approximately random."
      },
      {
        "isCorrect": true,
        "reason": "because the sampling procedure does not give every member of the population an equal chance of being selected. It is based on the analyst's convenience. Non - probability sampling depends on factors other than probability considerations, such as a sampler's judgment or the convenience to access data."
      },
      {
        "isCorrect": false,
        "reason": "because cluster sampling requires the division or classification of the population into subpopulation groups, called clusters. In this method, the population is divided into clusters, each of which is essentially a mini - representation of the entire populations. Then certain clusters are chosen as a whole using simple random sampling. If all the members in each sampled cluster are sampled, this sample plan is referred to as one - stage cluster sampling. If a subsample is randomly selected from each selected cluster, then the plan is referred as two - stage cluster sampling. Choosing only company names starting with the letter P is not two - stage cluster sampling."
      }
    ],
    "note": "Quantitative Methods: compare and contrast simple random, stratified random, cluster, convenience, and judgmental sampling and their implications for sampling error in an investment problem"
  },
  {
    "id": "QUA-74",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it fails to account for any compounding: (3% + 5%) = 8%, 90,000 (1.08) = 97,200."
      },
      {
        "isCorrect": false,
        "reason": "because it fails to account for quarterly compounding, 90,000(1.03) (1.05) = 97,335."
      },
      {
        "isCorrect": true,
        "reason": "because the returns are compounded quarterly,\n90,000(1 +\n0.03\n4 )4(1 +\n0.05\n4 )4 = 97,455"
      }
    ],
    "note": "Quantitative Methods: calculate and interpret annualized return measures and continuously compounded retums, and describe their appropriate uses"
  },
  {
    "id": "QUA-75",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because the two most noteworthy observations about the lognormal distribution are that it is bounded below by 0 and it is skewed to the right"
      },
      {
        "isCorrect": true,
        "reason": "because the two most noteworthy observations about the lognormal distribution are that it is bounded below by 0 and it is skewed to the right (it has a long right tail), i.e. it is asymmetrical."
      },
      {
        "isCorrect": false,
        "reason": "because like the normal distribution, the lognormal distribution is completely described by two parameters. Unlike the other distributions, a lognormal distribution is defined in terms of the parameters of a different distribution. The two parameters of a lognormal distribution are the mean and standard deviation (or variance) of its associated normal distribution. Remember, we must keep track of two sets of means and standard deviations (or variances) the mean and standard deviation (or variance) of the associated normal distribution (these are the parameters) and the mean and standard deviation (or variance) of the lognormal variable itself. The mean of the lognormal distribution is not equal to the mean of the associated normal distribution."
      }
    ],
    "note": "Quantitative Methods: explain the relationship between normal and lognormal distributions and why the lognormal distribution is used to model asset prices when using continuously compounded asset returns"
  },
  {
    "id": "QUA-76",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because a scatter plot (or scattergram) represents two variables in two dimensions. The variation of Y [the dependent variable] is often referred to as the sum of squares total (SST), or the total sum of squares."
      },
      {
        "isCorrect": true,
        "reason": "because the variation of Y [the dependent variable] is often referred to as the sum of squares total (SST), or the total sum of squares."
      },
      {
        "isCorrect": false,
        "reason": "Y [the dependent variable] is often referred to as the sum of squares total (SST), or the total sum of squares."
      }
    ],
    "note": "Quantitative Methods: describe a simple linear regression model, how the least squares criterion is used to estimate regression coefficients, and the interpretation of these coefficients"
  },
  {
    "id": "QUA-77",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because tokenization is the process of representing ownership rights to physical assets on a blockchain or distributed ledger."
      },
      {
        "isCorrect": false,
        "reason": "because an initial coin offering (ICO) is an unregulated process whereby companies sell their crypto tokens to investors in exchange for fiat money or for another agreed upon cryptocurrency."
      },
      {
        "isCorrect": false,
        "reason": "because a consensus mechanism is used to validate new transactions in the blockchain; it is not the process of representing ownership rights to physical assets. New transactions are inserted into the chain only after validation via a consensus mechanism in which authorized members agree on the transaction and the preceding order, or history, in which previous transactions have occurred. The consensus mechanism used to verify a transaction includes a cryptographic problem that must be solved by some computers on the network (known as miners) each time a transaction takes place."
      }
    ],
    "note": "Alternative Investments: describe financial applications of distributed ledger technology"
  },
  {
    "id": "QUA-78",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because using the equation PV=FVN (1 + rs/m) - Nm\nwhere\nm = number of compounding periods per year\nr = quoted annual interest rate\nN = number of years\nwe compute PV = $10,000,000 Ã— (1 + 0.05/2) - 15x2 = $4,767,426.85 ~ $4,767,427.\nIn applying the equation, we use the periodic rate (in this case, the semi - annual rate) and the appropriate number of periods with semi - annual compounding.\nN = 30; I/Y= 0.025; PMT = 0; FV = 10,000,000; CPT PV = $4,767,426.852 ~ $4,767,427"
      },
      {
        "isCorrect": false,
        "reason": "because when computing present value, it uses 5% instead of EAR to get $10,000,000 x (1.05) - 15= $4,810,170.98 ~ $4,810,171."
      },
      {
        "isCorrect": false,
        "reason": "because in the present value equation, it incorrectly accounts for compounding (multiplies by 2 instead of dividing) and does not use the appropriate number of periods for semi - annual compounding (divides by 2 instead of multiplying by 2); to incorrectly compute PV = 10,000,000 Ã— (1 + 0.05x2) - 15/2= $4,892,770.68 ~ $4,892,771."
      }
    ],
    "note": "Quantitative Methods: calculate and interpret annualized return measures and continuously compounded returns, and describe their appropriate uses"
  },
  {
    "id": "QUA-79",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because bitcoin is a well - known use of an open permissionless network. ."
      },
      {
        "isCorrect": false,
        "reason": "because miners verify transactions in the blockchain, they do not execute smart contracts. The consensus mechanism used to verify a transaction includes a cryptographic problem that must be solved by some computers on the network (known as miners) each time a transaction takes place. On the other hand, smart contracts are computer programs that self - execute on the basis of pre - specified terms and conditions agreed to by the parties to a contract."
      },
      {
        "isCorrect": true,
        "reason": "because through tokenization, the process of representing ownership rights to physical assets on a blockchain or distributed ledger, DLT [distributed ledger technology] has the potential to streamline this process by creating a single, digital record of ownership with which to verify ownership title and authenticity, including all historical activity."
      }
    ],
    "note": "Alternative Investments: describe financial applications of distributed ledger technology"
  },
  {
    "id": "QUA-80",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because we need to make the following four key assumptions to be able to draw valid conclusions from a simple linear regression model. One of those assumptions is that regression residuals are normally distributed."
      },
      {
        "isCorrect": false,
        "reason": "because one of the four underlying assumptions for simple linear regression is Independence: The observations, pairs of Ys and Xs, are independent of one another. This implies the regression residuals are uncorrelated [and do not have high correlation] across observations."
      },
      {
        "isCorrect": false,
        "reason": "because one of the four underlying assumptions for simple linear regression is Homoskedasticity: The variance of the regression residuals is the same [and not different] for all observations."
      }
    ],
    "note": "Quantitative Methods: explain the assumptions underlying the simple linear regression model, and describe how residuals and residual plots indicate if these assumptions may have been violated"
  },
  {
    "id": "QUA-81",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because when the observations are returns, the coefficient of variation measures the amount of risk (standard deviation) per unit of mean return."
      },
      {
        "isCorrect": false,
        "reason": "because it describes the Sharpe ratio, not the coefficient of variation. The Sharpe ratio measures the reward, in terms of mean excess return, per unit of risk, where mean excess return is defined as the average rate of return in excess of the risk - free rate."
      },
      {
        "isCorrect": false,
        "reason": "because it describes the mean absolute deviation (MAD), not the coefficient of variation. The MAD is defined as the mean of the absolute values of deviations from the sample mean."
      }
    ],
    "note": "Quantitative Methods: calculate, interpret, and evaluate measures of dispersion to address an investment problem"
  },
  {
    "id": "QUA-82",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because when the unknown population variances are equal, a t - test based on\nindependent random samples is given by t = (X1 - X2 - Î¼â‚ + Âµâ‚‚)/(SpÂ²/n1 + SpÂ²/n2)0.5, where Sp2 is a pooled estimator of the common variance. Hence, a change in hypothesized difference Âµ1 - Âµ2 will change the value of the test statistic."
      },
      {
        "isCorrect": false,
        "reason": "because the number of degrees of freedom is n, + nâ‚‚ - 2 and it is independent of the hypothesized difference Âµ1 - Âµ2."
      },
      {
        "isCorrect": false,
        "reason": "because sp2 = ((n1 - 1)s1Â² + (n2 - 1)s2Â²)/(n1 + nâ‚‚ - 2) is a pooled estimator of the common variance. It is independent of the hypothesized difference Âµ1 - Âµ2."
      }
    ],
    "note": "Quantitative Methods: construct hypothesis tests and determine their statistical significance, the associated Type I and Type II errors, and power of the test given a significance level"
  },
  {
    "id": "QUA-83",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because with n as the sample size, the Spearman rank correlation is given by:\nrs = 1 - (6 Î£di2)/(n(n2 â€“ 1)) = 1 âˆ’ 6(12)/(4(42 - 1)) = 1 - 6/5= - 1/5 = - 0.2, where the sum of squared differences\nin ranks Î£di2 = (2 - 1)2 + (3 - 2)2 + (4 - 3)2 + (1 - 4)2 = 1 + 1 + 1 + 9 = 12."
      },
      {
        "isCorrect": false,
        "reason": "because this answer is calculated by erroneously omitting the multiple (of the sum of squared deviations) of 6, giving a rank correlation of 1 - 1/5 = 4/5 = 0.8."
      },
      {
        "isCorrect": false,
        "reason": "because instead of using the sum of squared differences in ranks, this answer erroneously uses the sum of unsquared differences in ranks (which, by definition, sums to zero), giving a rank correlation of 1."
      }
    ],
    "note": "Quantitative Methods: explain parametric and nonparametric tests of the hypothesis that the population correlation coefficient equals zero, and determine whether the hypothesis is rejected at a given level of significance"
  },
  {
    "id": "QUA-84",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because variation in the supply of wheat is a dependent variable not limited to values of 0 or 1. Suppose we want to examine whether a company's quarterly earnings announcements influence its monthly stock returns. In this case, we could use an indicator variable, or dummy variable, that takes on only the values 0 or 1 as the independent variable."
      },
      {
        "isCorrect": true,
        "reason": "because variation in the demand for corn is being used to explain the variation in the supply of wheat. Therefore the variation in the supply of wheat is the dependent variable, or explained variable. We refer to the variable whose variation is being explained as the dependent variable, or the explained variable, it is typically denoted by Y."
      },
      {
        "isCorrect": false,
        "reason": "because the variation in the demand for corn is being used to explain the variation in the supply of wheat. Therefore the variation in the demand for corn is the independent variable. We refer to the variable whose variation is being used to explain the variation of the dependent variable as the independent variable, or the explanatory variable, it is typically denoted by X."
      }
    ],
    "note": "Quantitative Methods: describe a simple linear regression model, how the least squares criterion is used to estimate regression coefficients, and the interpretation of these coefficients"
  },
  {
    "id": "QUA-85",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because a return distribution with negative skew has frequent small gains and a few extreme losses."
      },
      {
        "isCorrect": false,
        "reason": "because a return distribution with positive skew has frequent small losses and a few extreme gains. A return distribution with negative skew has frequent small gains and a few extreme losses."
      },
      {
        "isCorrect": false,
        "reason": "because a return distribution with positive skew has frequent small losses and a few extreme gains. A\neturn distribution with negative skew has frequent small gains and a few extreme losses."
      }
    ],
    "note": "Quantitative Methods: interpret and evaluate measures of skewness and kurtosis to address an investment problem"
  },
  {
    "id": "QUA-86",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because when we look at the residuals of a model, what we would like to see is that the residuals are random. The residuals should not exhibit a pattern when plotted against the independent variable."
      },
      {
        "isCorrect": true,
        "reason": "because when we look at the residuals of a model, what we would like to see is that the residuals are random. The residuals should not exhibit a pattern when plotted against the independent variable."
      },
      {
        "isCorrect": false,
        "reason": "because when we look at the residuals of a model, what we would like to see is that the residuals are random. The residuals should not exhibit a pattern when plotted against the independent variable."
      }
    ],
    "note": "Quantitative Methods: explain the assumptions underlying the simple linear regression model, and describe how residuals and residual plots indicate if these assumptions may have been violated"
  },
  {
    "id": "QUA-87",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because, in cluster sampling, the population is divided into clusters, each of which is essentially a mini - representation of the entire populations. Then certain clusters are chosen as a whole using simple random sampling Cluster sampling is commonly used for market surveys, and the most popular version identifies clusters based on geographic parameters."
      },
      {
        "isCorrect": false,
        "reason": "because judgmental, not cluster, sampling involves selectively handpicking elements from the population based on a researcher's knowledge and professional judgment. For example, when auditing financial statements, seasoned auditors can apply\ntheir sound judgment to select accounts or transactions that can provide sufficient audit coverage."
      },
      {
        "isCorrect": false,
        "reason": "because creating a bond portfolio to mirror the performance of a specified index is an application of stratified sampling. Bond indexing is one area in which stratified sampling, rather than cluster sampling, is frequently applied. Indexing is an investment strategy in which an investor constructs a portfolio to mirror the performance of a specified index."
      }
    ],
    "note": "Quantitative Methods: compare and contrast simple random, stratified random, cluster, convenience, and judgmental sampling and their implications for sampling error in an investment problem"
  },
  {
    "id": "QUA-88",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because it is the underlying binomial distribution that exhibits skewness when p â‰  0.5, not the sampling distribution of the sample mean. Since the sample size is large, the distribution of the sample mean will be approximately normal according to the central limit theorem, and therefore symmetric."
      },
      {
        "isCorrect": true,
        "reason": "because, according to the central limit theorem, the sampling distribution of the sample mean will be approximately normal when the sample size n is large. The normal distribution has a skewness of 0 (it is symmetric). Since the binomial distribution has a mean of np and finite variance of np(1 - p), where n is the number of trials and p is the probability of success, the central limit theorem holds."
      },
      {
        "isCorrect": false,
        "reason": "because it is the underlying binomial distribution that exhibits skewness when p â‰  0.5, not the sampling distribution of the sample mean. Since the sample size is large, the distribution of the sample mean will be approximately normal according to the central limit theorem, and therefore symmetric."
      }
    ],
    "note": "Quantitative Methods: explain the central limit theorem and its importance for the distribution and standard error of the sample mean"
  },
  {
    "id": "QUA-89",
    "solutions": [
      {
        "isCorrect": true,
        "reason": ". A negatively skewed distribution appears as if the left tail has been pulled away from the mean. The average magnitude of negative deviations from the mean is larger than the average magnitude of positive deviations."
      },
      {
        "isCorrect": false,
        "reason": ". Kurtosis refers to relative peakedness of a distribution; leptokurtosis means more peaked than normal."
      },
      {
        "isCorrect": false,
        "reason": ". A negatively skewed distribution appears as if the left tail has been pulled away from the mean."
      }
    ],
    "note": "Quantitative Methods: interpret and evaluate measures of skewness and kurtosis to address an investment problem"
  },
  {
    "id": "QUA-90",
    "solutions": [
      {
        "isCorrect": false,
        "reason": ". Tests related to differences between means concern a parameter. Nonparametric tests are used when the data do not concern a parameter or the data do not meet distributional assumptions."
      },
      {
        "isCorrect": true,
        "reason": ". A nonparametric test is used under three circumstances:\n1) when the data do not meet distributional assumptions,\n2) when the data are given in ranks\nand\n3) when the hypothesis does not concern a parameter."
      },
      {
        "isCorrect": false,
        "reason": ", When the data meet distributional assumptions, a parametric test is used instead of a nonparametric test."
      }
    ],
    "note": "Quantitative Methods: compare and contrast appropriate type of test parametric and nonparametric tests, and describe situations where each is the more"
  },
  {
    "id": "QUA-91",
    "solutions": [
      {
        "isCorrect": true,
        "reason": "because the time - weighted rate of return is the preferred performance measure as it neutralizes the effect of cash withdrawals or additions to the portfolio, which are generally outside of the control of the portfolio manager."
      },
      {
        "isCorrect": false,
        "reason": "because the arithmetic return is biased upward. For the evaluation of portfolios of publicly traded securities, the time - weighted rate of return is the preferred performance measure."
      },
      {
        "isCorrect": false,
        "reason": "because investment managers find time - weighted returns more meaningful. If a client gives an investment manager more funds to invest at an unfavorable time, the manager's money - weighted rate of return will tend to be depressed. If a client adds funds at a favorable time, the money - weighted return will tend to be elevated. The time - weighted rate of return removes these effects."
      }
    ],
    "note": "Quantitative Methods: compare the money - weighted and time - weighted rates of return and evaluate the performance of portfolios based on these measures"
  },
  {
    "id": "QUA-92",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because, in cluster sampling, the population is divided into clusters, each of which is essentially a mini - representation of the entire populations. Then certain clusters are chosen as a whole using simple random sampling. The sampling method used by the analyst is not cluster sampling because, first, each sector is not a mini - representation of all public firms, second, certain sectors are not chosen as a whole."
      },
      {
        "isCorrect": false,
        "reason": "because, in simple random sampling, a public firm would be randomly selected without the firms being grouped into sectors first. A simple random sample is a subset of a larger population created in such a way that each element of the population has an equal probability of being selected to the subset."
      },
      {
        "isCorrect": true,
        "reason": "because, in stratified random sampling, the population is divided into subpopulations (strata) based on one or more classification criteria. Simple random samples are then drawn from each stratum in sizes proportional to the relative size of each stratum in the population"
      }
    ],
    "note": "Quantitative Methods: compare and contrast simple random, stratified random, cluster, convenience, and judgmental sampling and their implications for sampling error in an investment problem"
  },
  {
    "id": "QUA-93",
    "solutions": [
      {
        "isCorrect": false,
        "reason": "because if we mistakenly reject the null hypothesis, we can only be making a Type I error."
      },
      {
        "isCorrect": false,
        "reason": "because rejecting a false null hypothesis is a correct decision and therefore not a Type II error."
      },
      {
        "isCorrect": true,
        "reason": "because, when we make a decision in a hypothesis test, we run the risk of making either a Type I or a Type II error. These are mutually exclusive errors: If we mistakenly reject the null hypothesis, we can only be making a Type I error, if we mistakenly fail to reject the null, we can only be making a Type II error."
      }
    ],
    "note": "Quantitative Methods: explain hypothesis testing and its components, including statistical significance, Type I and Type II errors, and the power of a test."
  }
]